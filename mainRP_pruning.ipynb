{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone RIFE repository\n",
        "!git clone https://github.com/hzwer/arXiv2020-RIFE.git\n",
        "%cd arXiv2020-RIFE\n",
        "!pip install git+https://github.com/rk-exxec/scikit-video.git@numpy_deprecation\n",
        "!pip install thop  # For FLOPs calculation\n",
        "\n",
        "# Copy the zip file WITH destination specified\n",
        "!cp \"/content/drive/MyDrive/RIFE_weights/RIFE_trained_v6.zip\" ./\n",
        "\n",
        "# Extract the zip file (using unzip as alternative if 7z has issues)\n",
        "!unzip -q RIFE_trained_v6.zip || 7z x RIFE_trained_v6.zip\n",
        "\n",
        "# Fix nested train_log structure\n",
        "!if [ -d \"RIFE_trained_v6/train_log\" ]; then mv RIFE_trained_v6/train_log ./train_log; fi\n",
        "!if [ -d \"train_log/train_log\" ]; then mv train_log/train_log ./train_log_fixed && rm -rf train_log && mv train_log_fixed train_log; fi\n",
        "\n",
        "# Alternative: if train_log is directly in RIFE_trained_v6 root\n",
        "!if [ -d \"RIFE_trained_v6\" ] && [ ! -d \"train_log\" ]; then mv RIFE_trained_v6 train_log; fi\n",
        "\n",
        "print(\"\\nContents of train_log:\")\n",
        "!ls -la train_log || echo \"train_log folder not found!\"\n",
        "\n",
        "print(\"\\nRequired model files:\")\n",
        "!ls -la train_log/*.pkl 2>/dev/null || echo \"Model .pkl files not found!\"\n",
        "\n",
        "# Verify dataset path\n",
        "UCF_PATH = \"/content/drive/MyDrive/UCF-101/ucf101_interp_ours\"\n",
        "\n",
        "import os\n",
        "if not os.path.exists(UCF_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset path not found: {UCF_PATH}\")\n",
        "else:\n",
        "    print(f\"\\nDataset path found: {UCF_PATH}\")\n",
        "\n",
        "# Load required libraries\n",
        "import cv2, math, torch, numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from thop import profile, clever_format\n",
        "from torch.nn import functional as F\n",
        "from model.pytorch_msssim import ssim_matlab\n",
        "from model.RIFE import Model\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load model\n",
        "model = Model()\n",
        "model.load_model('train_log')\n",
        "model.eval()\n",
        "model.device()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Calculate model parameters - access the actual PyTorch modules\n",
        "def count_parameters(model):\n",
        "    total = 0\n",
        "    # RIFE Model has flownet attribute which is the actual nn.Module\n",
        "    if hasattr(model, 'flownet'):\n",
        "        total += sum(p.numel() for p in model.flownet.parameters())\n",
        "    # Check for other submodules\n",
        "    for attr_name in dir(model):\n",
        "        attr = getattr(model, attr_name)\n",
        "        if isinstance(attr, torch.nn.Module) and attr_name != 'flownet':\n",
        "            total += sum(p.numel() for p in attr.parameters())\n",
        "    return total\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "print(f\"Total Parameters: {total_params:,} ({total_params/1e6:.2f}M)\")\n",
        "\n",
        "# Calculate FLOPs (using a sample input)\n",
        "sample_img0 = torch.randn(1, 3, 256, 256).to(device)\n",
        "sample_img1 = torch.randn(1, 3, 256, 256).to(device)\n",
        "\n",
        "flops_str = \"N/A\"\n",
        "try:\n",
        "    # For RIFE, we need to profile the flownet specifically\n",
        "    with torch.no_grad():\n",
        "        # RIFE's inference method\n",
        "        flops, params = profile(model.flownet, inputs=(torch.cat([sample_img0, sample_img1], 1),), verbose=False)\n",
        "    flops_str, params_str = clever_format([flops, params], \"%.3f\")\n",
        "    print(f\"FLOPs (256x256 input): {flops_str}\")\n",
        "    print(f\"Params (from profiler): {params_str}\")\n",
        "except Exception as e:\n",
        "    print(f\"FLOPs calculation note: Using model.flownet for profiling\")\n",
        "    try:\n",
        "        # Alternative: just count FLOPs for flownet\n",
        "        with torch.no_grad():\n",
        "            flops = profile(model.flownet, inputs=(torch.cat([sample_img0, sample_img1], 1),), verbose=False)[0]\n",
        "        flops_str = clever_format([flops], \"%.3f\")[0]\n",
        "        print(f\"FLOPs (256x256 input): {flops_str}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"FLOPs calculation failed: {e2}\")\n",
        "        flops_str = \"N/A\"\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Evaluate on UCF-101\n",
        "dirs = os.listdir(UCF_PATH)\n",
        "psnr_list, ssim_list, time_list = [], [], []\n",
        "memory_list = []\n",
        "\n",
        "print(f\"Starting evaluation on {len(dirs)} sequences...\\n\")\n",
        "\n",
        "# Warm-up runs\n",
        "print(\"Performing warm-up runs...\")\n",
        "sample_img0 = torch.randn(1, 3, 256, 256).to(device)\n",
        "sample_img1 = torch.randn(1, 3, 256, 256).to(device)\n",
        "for _ in range(3):\n",
        "    with torch.no_grad():\n",
        "        _ = model.inference(sample_img0, sample_img1)\n",
        "\n",
        "# Clear cache and measure baseline memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "    baseline_memory = torch.cuda.memory_allocated() / (1024**2)  # MB\n",
        "    print(f\"Baseline GPU memory: {baseline_memory:.2f} MB\")\n",
        "\n",
        "print(\"Warm-up complete.\\n\")\n",
        "\n",
        "# Use tqdm for progress bar\n",
        "for d in tqdm(dirs, desc=\"Evaluating\", unit=\"seq\"):\n",
        "    img0_path = os.path.join(UCF_PATH, d, 'frame_00.png')\n",
        "    img1_path = os.path.join(UCF_PATH, d, 'frame_02.png')\n",
        "    gt_path   = os.path.join(UCF_PATH, d, 'frame_01_gt.png')\n",
        "\n",
        "    if not all(map(os.path.exists, [img0_path, img1_path, gt_path])):\n",
        "        tqdm.write(f\"Missing frames in {d}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    img0 = torch.tensor(cv2.imread(img0_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "    img1 = torch.tensor(cv2.imread(img1_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "    gt   = torch.tensor(cv2.imread(gt_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "\n",
        "    # Reset peak memory stats before inference\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        mem_before = torch.cuda.memory_allocated() / (1024**2)  # MB\n",
        "\n",
        "    # Measure inference time\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "    start_time = time.time()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pred = model.inference(img0, img1)[0]\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.synchronize()\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Measure peak memory usage during inference\n",
        "    if torch.cuda.is_available():\n",
        "        mem_after = torch.cuda.memory_allocated() / (1024**2)  # MB\n",
        "        peak_mem = torch.cuda.max_memory_allocated() / (1024**2)  # MB\n",
        "        memory_used = peak_mem - mem_before\n",
        "        memory_list.append(memory_used)\n",
        "\n",
        "    inference_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
        "    time_list.append(inference_time)\n",
        "\n",
        "    # Calculate SSIM - FIXED: removed extra parenthesis\n",
        "    ssim = ssim_matlab(gt, torch.round(pred*255).unsqueeze(0)/255).detach().cpu().numpy()\n",
        "\n",
        "    # Calculate PSNR\n",
        "    out = pred.detach().cpu().numpy().transpose(1,2,0)\n",
        "    out = np.round(out*255)/255.\n",
        "    gt_np = gt[0].cpu().numpy().transpose(1,2,0)\n",
        "    psnr = -10 * math.log10(((gt_np - out)**2).mean())\n",
        "\n",
        "    psnr_list.append(psnr)\n",
        "    ssim_list.append(ssim)\n",
        "\n",
        "# Calculate memory statistics\n",
        "if torch.cuda.is_available():\n",
        "    total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**2)  # MB\n",
        "    current_memory = torch.cuda.memory_allocated() / (1024**2)  # MB\n",
        "    peak_memory = torch.cuda.max_memory_allocated() / (1024**2)  # MB\n",
        "    reserved_memory = torch.cuda.memory_reserved() / (1024**2)  # MB\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Dataset: UCF-101\")\n",
        "print(f\"Total Sequences Evaluated: {len(psnr_list)}\")\n",
        "print(\"-\"*60)\n",
        "print(\"Quality Metrics:\")\n",
        "print(f\"  Average PSNR: {np.mean(psnr_list):.3f} dB\")\n",
        "print(f\"  Average SSIM: {np.mean(ssim_list):.4f}\")\n",
        "print(\"-\"*60)\n",
        "print(\"Speed Metrics:\")\n",
        "print(f\"  Average Inference Time: {np.mean(time_list):.2f} ms\")\n",
        "print(f\"  FPS: {1000/np.mean(time_list):.2f}\")\n",
        "print(f\"  Min Inference Time: {np.min(time_list):.2f} ms\")\n",
        "print(f\"  Max Inference Time: {np.max(time_list):.2f} ms\")\n",
        "print(f\"  Std Dev Inference Time: {np.std(time_list):.2f} ms\")\n",
        "print(\"-\"*60)\n",
        "print(\"Memory Usage:\")\n",
        "if torch.cuda.is_available() and len(memory_list) > 0:\n",
        "    print(f\"  Average Memory per Frame: {np.mean(memory_list):.2f} MB\")\n",
        "    print(f\"  Peak Memory per Frame: {np.max(memory_list):.2f} MB\")\n",
        "    print(f\"  Min Memory per Frame: {np.min(memory_list):.2f} MB\")\n",
        "    print(f\"  Current GPU Memory: {current_memory:.2f} MB\")\n",
        "    print(f\"  Peak GPU Memory: {peak_memory:.2f} MB\")\n",
        "    print(f\"  Reserved GPU Memory: {reserved_memory:.2f} MB\")\n",
        "    print(f\"  Total GPU Memory: {total_memory:.2f} MB\")\n",
        "else:\n",
        "    print(f\"  Memory tracking not available (CPU mode)\")\n",
        "print(\"-\"*60)\n",
        "print(\"Model Complexity:\")\n",
        "print(f\"  Parameters: {total_params:,} ({total_params/1e6:.2f}M)\")\n",
        "print(f\"  FLOPs (256x256): {flops_str}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaWaMvcpYAkG",
        "outputId": "a5c34832-6ebd-46ef-a068-52f80f30bdc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'arXiv2020-RIFE'...\n",
            "remote: Enumerating objects: 2037, done.\u001b[K\n",
            "remote: Counting objects: 100% (461/461), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 2037 (delta 423), reused 360 (delta 360), pack-reused 1576 (from 2)\u001b[K\n",
            "Receiving objects: 100% (2037/2037), 4.12 MiB | 11.01 MiB/s, done.\n",
            "Resolving deltas: 100% (1293/1293), done.\n",
            "/content/arXiv2020-RIFE\n",
            "Collecting git+https://github.com/rk-exxec/scikit-video.git@numpy_deprecation\n",
            "  Cloning https://github.com/rk-exxec/scikit-video.git (to revision numpy_deprecation) to /tmp/pip-req-build-q6accp29\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rk-exxec/scikit-video.git /tmp/pip-req-build-q6accp29\n",
            "  Running command git checkout -b numpy_deprecation --track origin/numpy_deprecation\n",
            "  Switched to a new branch 'numpy_deprecation'\n",
            "  Branch 'numpy_deprecation' set up to track remote branch 'numpy_deprecation' from 'origin'.\n",
            "  Resolved https://github.com/rk-exxec/scikit-video.git to commit 74cbbb2e19599304bf069529537b23a518fdc3c9\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scikit-video==1.1.11) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from scikit-video==1.1.11) (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from scikit-video==1.1.11) (11.3.0)\n",
            "Building wheels for collected packages: scikit-video\n",
            "  Building wheel for scikit-video (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-video: filename=scikit_video-1.1.11-py3-none-any.whl size=2247110 sha256=6a4a52eef3e3a5c1db7abdad674a0f49a688e6b420dbcf631f427abd93726e8a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bmjuvxhg/wheels/85/b9/25/cbfd7f5b1956810f105940e9aba020b6d642fdb373004f7d4a\n",
            "Successfully built scikit-video\n",
            "Installing collected packages: scikit-video\n",
            "Successfully installed scikit-video-1.1.11\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from thop) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->thop) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->thop) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->thop) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->thop) (3.0.3)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "\n",
            "Contents of train_log:\n",
            "total 41916\n",
            "drwxr-xr-x 3 root root     4096 Aug 13  2021 .\n",
            "drwxr-xr-x 9 root root     4096 Nov 10 17:29 ..\n",
            "-rw-r--r-- 1 root root     6148 Aug 13  2021 .DS_Store\n",
            "-rw-r--r-- 1 root root 42901317 Aug 13  2021 flownet.pkl\n",
            "drwxr-xr-x 2 root root     4096 Jun 17  2021 __pycache__\n",
            "\n",
            "Required model files:\n",
            "-rw-r--r-- 1 root root 42901317 Aug 13  2021 train_log/flownet.pkl\n",
            "\n",
            "Dataset path found: /content/drive/MyDrive/UCF-101/ucf101_interp_ours\n",
            "Using device: cuda\n",
            "\n",
            "============================================================\n",
            "MODEL STATISTICS\n",
            "============================================================\n",
            "Total Parameters: 10,708,215 (10.71M)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/thop/vision/calc_func.py:53: UserWarning: This API is being deprecated\n",
            "  warnings.warn(\"This API is being deprecated\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs (256x256 input): 11.684G\n",
            "Params (from profiler): 10.072M\n",
            "============================================================\n",
            "\n",
            "Starting evaluation on 379 sequences...\n",
            "\n",
            "Performing warm-up runs...\n",
            "Baseline GPU memory: 43.80 MB\n",
            "Warm-up complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 379/379 [11:25<00:00,  1.81s/seq]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS\n",
            "============================================================\n",
            "Dataset: UCF-101\n",
            "Total Sequences Evaluated: 379\n",
            "------------------------------------------------------------\n",
            "Quality Metrics:\n",
            "  Average PSNR: 35.292 dB\n",
            "  Average SSIM: 0.9690\n",
            "------------------------------------------------------------\n",
            "Speed Metrics:\n",
            "  Average Inference Time: 14.16 ms\n",
            "  FPS: 70.60\n",
            "  Min Inference Time: 13.45 ms\n",
            "  Max Inference Time: 23.23 ms\n",
            "  Std Dev Inference Time: 1.32 ms\n",
            "------------------------------------------------------------\n",
            "Memory Usage:\n",
            "  Average Memory per Frame: 33.93 MB\n",
            "  Peak Memory per Frame: 33.93 MB\n",
            "  Min Memory per Frame: 33.93 MB\n",
            "  Current GPU Memory: 46.80 MB\n",
            "  Peak GPU Memory: 80.73 MB\n",
            "  Reserved GPU Memory: 104.00 MB\n",
            "  Total GPU Memory: 15095.06 MB\n",
            "------------------------------------------------------------\n",
            "Model Complexity:\n",
            "  Parameters: 10,708,215 (10.71M)\n",
            "  FLOPs (256x256): 11.684G\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoJ_NJ6HXUX4",
        "outputId": "1a096c34-cab8-4bad-e33c-9495f7a08bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 1: PRUNING EXPERIMENTS\n",
            "============================================================\n",
            "‚úÖ Using model from previous cell\n",
            "‚úÖ Dataset path verified: /content/drive/MyDrive/UCF-101/ucf101_interp_ours\n",
            "\n",
            "Baseline metrics (from full evaluation):\n",
            "  PSNR: 35.292 dB\n",
            "  SSIM: 0.9690\n",
            "\n",
            "Verifying baseline on subset (20 samples)...\n",
            "Quick evaluation on 20 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline quick check - PSNR: 36.641 dB, SSIM: 0.9810\n",
            "\n",
            "============================================================\n",
            "STEP 1: Computing Channel Importance\n",
            "============================================================\n",
            "Analyzed 57 convolutional layers\n",
            "\n",
            "============================================================\n",
            "STEP 2: Testing Different Sparsity Levels\n",
            "============================================================\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 30.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Sparsity: 30.0%, Threshold: 40.140980\n",
            "Actual pruning: 2058/6858 channels (30.0%)\n",
            "Applying pruning masks...\n",
            "Evaluating pruned model (50 samples)...\n",
            "Quick evaluation on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "  PSNR: 25.319 dB (drop: 9.973 dB)\n",
            "  SSIM: 0.8772 (drop: 0.0918)\n",
            "  Inference: 11.63 ms (86.0 FPS)\n",
            "  Est. Param Reduction: ~30%\n",
            "  Speedup vs baseline: 1.16x\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 50.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Sparsity: 50.0%, Threshold: 73.872589\n",
            "Actual pruning: 3430/6858 channels (50.0%)\n",
            "Applying pruning masks...\n",
            "Evaluating pruned model (50 samples)...\n",
            "Quick evaluation on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "  PSNR: 32.364 dB (drop: 2.928 dB)\n",
            "  SSIM: 0.9623 (drop: 0.0067)\n",
            "  Inference: 10.24 ms (97.6 FPS)\n",
            "  Est. Param Reduction: ~50%\n",
            "  Speedup vs baseline: 1.32x\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 70.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Sparsity: 70.0%, Threshold: 104.645721\n",
            "Actual pruning: 4801/6858 channels (70.0%)\n",
            "Applying pruning masks...\n",
            "Evaluating pruned model (50 samples)...\n",
            "Quick evaluation on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "  PSNR: 32.663 dB (drop: 2.629 dB)\n",
            "  SSIM: 0.9629 (drop: 0.0061)\n",
            "  Inference: 10.39 ms (96.2 FPS)\n",
            "  Est. Param Reduction: ~70%\n",
            "  Speedup vs baseline: 1.30x\n",
            "\n",
            "============================================================\n",
            "SPARSITY SELECTION\n",
            "============================================================\n",
            "Sparsity 30.0%: PSNR=25.319 dB (drop: 9.973 dB), SSIM=0.8772\n",
            "Sparsity 50.0%: PSNR=32.364 dB (drop: 2.928 dB), SSIM=0.9623\n",
            "Sparsity 70.0%: PSNR=32.663 dB (drop: 2.629 dB), SSIM=0.9629\n",
            "‚ö†Ô∏è  No sparsity level meets target drop of 0.5 dB\n",
            "    Selecting least aggressive option (30%)\n",
            "\n",
            "============================================================\n",
            "STEP 3: Creating Final Pruned Model\n",
            "============================================================\n",
            "Selected sparsity: 30.0%\n",
            "Sparsity: 30.0%, Threshold: 40.140980\n",
            "Actual pruning: 2058/6858 channels (30.0%)\n",
            "\n",
            "============================================================\n",
            "STEP 4: Comprehensive Evaluation\n",
            "============================================================\n",
            "Evaluating on FULL UCF-101 dataset (379 sequences)...\n",
            "‚è±Ô∏è  This may take 5-10 minutes...\n",
            "Quick evaluation on 379 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL RESULTS\n",
            "============================================================\n",
            "\n",
            "üìä Baseline Model:\n",
            "  PSNR: 35.292 dB\n",
            "  SSIM: 0.9690\n",
            "  Parameters: 10,708,215 (10.71M)\n",
            "\n",
            "üìä Pruned Model (Sparsity: 30.0%):\n",
            "  PSNR: 24.607 dB (Œî: 10.685 dB)\n",
            "  SSIM: 0.8563 (Œî: 0.1127)\n",
            "  Inference Time: 10.86 ms\n",
            "  FPS: 92.1\n",
            "  Est. Param Reduction: ~30%\n",
            "\n",
            "üíæ Results saved to '/content/pruning_results.json'\n",
            "üíæ Pruned model saved to '/content/pruned_model_checkpoint.pth'\n",
            "\n",
            "============================================================\n",
            "‚úÖ PRUNING PHASE COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Next steps:\n",
            "  1. Review results in 'pruning_results.json'\n",
            "  2. Proceed to fine-tuning (if PSNR drop > 0.3 dB)\n",
            "  3. Or proceed to quantization phase\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# COMPLETE PRUNING PIPELINE - CORRECTED VERSION\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import json\n",
        "\n",
        "# ============================================================\n",
        "# HELPER FUNCTIONS FOR PRUNING (FIXED)\n",
        "# ============================================================\n",
        "\n",
        "def compute_channel_importance(module, layer_types=[nn.Conv2d]):\n",
        "    \"\"\"\n",
        "    Compute L1-norm importance for each channel in convolutional layers.\n",
        "\n",
        "    Args:\n",
        "        module: Neural network module (e.g., model.flownet)\n",
        "        layer_types: Types of layers to analyze\n",
        "\n",
        "    Returns:\n",
        "        importance_dict: Dictionary mapping layer names to importance scores\n",
        "    \"\"\"\n",
        "    importance_dict = {}\n",
        "\n",
        "    for name, layer in module.named_modules():\n",
        "        if isinstance(layer, tuple(layer_types)):\n",
        "            # For Conv2d: weight shape is [out_channels, in_channels, H, W]\n",
        "            # Importance = L1 norm across all dimensions except out_channels\n",
        "            weight = layer.weight.data\n",
        "            importance = torch.norm(weight.view(weight.size(0), -1), p=1, dim=1)\n",
        "            importance_dict[name] = importance.cpu()\n",
        "\n",
        "    print(f\"Analyzed {len(importance_dict)} convolutional layers\")\n",
        "    return importance_dict\n",
        "\n",
        "\n",
        "def global_channel_pruning(importance_dict, sparsity=0.5):\n",
        "    \"\"\"\n",
        "    Create pruning masks based on global importance ranking.\n",
        "\n",
        "    Args:\n",
        "        importance_dict: Channel importance scores from compute_channel_importance()\n",
        "        sparsity: Fraction of channels to prune (0-1)\n",
        "\n",
        "    Returns:\n",
        "        prune_masks: Dictionary of boolean masks for each layer\n",
        "    \"\"\"\n",
        "    # Flatten all importance scores\n",
        "    all_importance = torch.cat([imp for imp in importance_dict.values()])\n",
        "\n",
        "    # Determine threshold (prune channels below this)\n",
        "    num_to_prune = int(len(all_importance) * sparsity)\n",
        "    threshold = torch.sort(all_importance)[0][num_to_prune]\n",
        "\n",
        "    print(f\"Sparsity: {sparsity:.1%}, Threshold: {threshold:.6f}\")\n",
        "\n",
        "    # Create masks (True = keep, False = prune)\n",
        "    prune_masks = {}\n",
        "    total_channels = 0\n",
        "    pruned_channels = 0\n",
        "\n",
        "    for name, importance in importance_dict.items():\n",
        "        mask = (importance > threshold)\n",
        "        prune_masks[name] = mask\n",
        "\n",
        "        total_channels += len(mask)\n",
        "        pruned_channels += (~mask).sum().item()\n",
        "\n",
        "    actual_sparsity = pruned_channels / total_channels\n",
        "    print(f\"Actual pruning: {pruned_channels}/{total_channels} channels ({actual_sparsity:.1%})\")\n",
        "\n",
        "    return prune_masks\n",
        "\n",
        "\n",
        "def apply_soft_pruning(model, prune_masks):\n",
        "    \"\"\"\n",
        "    Apply soft pruning by zeroing out weights (doesn't change model structure).\n",
        "    This is fast for testing different sparsity levels.\n",
        "\n",
        "    Args:\n",
        "        model: RIFE model\n",
        "        prune_masks: Dictionary of pruning masks\n",
        "\n",
        "    Returns:\n",
        "        pruned_model: Model with zeroed weights\n",
        "    \"\"\"\n",
        "    from model.RIFE import Model as RIFEModel\n",
        "\n",
        "    # Create a deep copy\n",
        "    pruned_model = RIFEModel()\n",
        "    pruned_model.load_model('train_log')  # Reload from checkpoint\n",
        "    pruned_model.eval()\n",
        "\n",
        "    # Apply masks\n",
        "    for name, module in pruned_model.flownet.named_modules():\n",
        "        if name in prune_masks:\n",
        "            mask = prune_masks[name]\n",
        "\n",
        "            # Get device from module\n",
        "            device = next(module.parameters()).device\n",
        "\n",
        "            # Expand mask to match weight dimensions [out_ch, in_ch, H, W]\n",
        "            weight_mask = mask.view(-1, 1, 1, 1).expand_as(module.weight).to(device)\n",
        "\n",
        "            # Zero out pruned channels\n",
        "            module.weight.data *= weight_mask\n",
        "\n",
        "            if module.bias is not None:\n",
        "                bias_mask = mask.to(device)\n",
        "                module.bias.data *= bias_mask\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "\n",
        "def quick_evaluate(model, dataset_path, num_samples=50):\n",
        "    \"\"\"\n",
        "    Quick evaluation on a subset of data for rapid testing.\n",
        "    FIXED: Works with RIFE's custom Model class\n",
        "\n",
        "    Args:\n",
        "        model: RIFE model to evaluate\n",
        "        dataset_path: Path to dataset (e.g., UCF-101)\n",
        "        num_samples: Number of sequences to test\n",
        "\n",
        "    Returns:\n",
        "        results: Dictionary with PSNR, SSIM, inference time\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    import math\n",
        "    from model.pytorch_msssim import ssim_matlab\n",
        "\n",
        "    # RIFE model is already on correct device\n",
        "    model.eval()\n",
        "\n",
        "    # Detect device from model parameters\n",
        "    device = next(model.flownet.parameters()).device\n",
        "\n",
        "    # Get list of sequences\n",
        "    dirs = os.listdir(dataset_path)\n",
        "    dirs = dirs[:num_samples]  # Limit to num_samples\n",
        "\n",
        "    psnr_list, ssim_list, time_list = [], [], []\n",
        "\n",
        "    print(f\"Quick evaluation on {len(dirs)} samples...\")\n",
        "\n",
        "    for d in tqdm(dirs, desc=\"Evaluating\", leave=False):\n",
        "        img0_path = os.path.join(dataset_path, d, 'frame_00.png')\n",
        "        img1_path = os.path.join(dataset_path, d, 'frame_02.png')\n",
        "        gt_path = os.path.join(dataset_path, d, 'frame_01_gt.png')\n",
        "\n",
        "        if not all(map(os.path.exists, [img0_path, img1_path, gt_path])):\n",
        "            continue\n",
        "\n",
        "        # Load images\n",
        "        img0 = torch.tensor(cv2.imread(img0_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "        img1 = torch.tensor(cv2.imread(img1_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "        gt = torch.tensor(cv2.imread(gt_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "\n",
        "        # Inference with timing\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        start_time = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model.inference(img0, img1)[0]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        inference_time = (time.time() - start_time) * 1000\n",
        "        time_list.append(inference_time)\n",
        "\n",
        "        # Compute SSIM\n",
        "        ssim_val = ssim_matlab(gt, torch.round(pred*255).unsqueeze(0)/255).detach().cpu().numpy()\n",
        "        ssim_list.append(float(ssim_val))\n",
        "\n",
        "        # Compute PSNR\n",
        "        out = pred.detach().cpu().numpy().transpose(1,2,0)\n",
        "        out = np.round(out*255)/255.\n",
        "        gt_np = gt[0].cpu().numpy().transpose(1,2,0)\n",
        "        mse = ((gt_np - out)**2).mean()\n",
        "        psnr = -10 * math.log10(mse + 1e-8)\n",
        "        psnr_list.append(psnr)\n",
        "\n",
        "    if len(psnr_list) == 0:\n",
        "        raise ValueError(f\"No valid samples found in {dataset_path}\")\n",
        "\n",
        "    results = {\n",
        "        'PSNR': np.mean(psnr_list),\n",
        "        'SSIM': np.mean(ssim_list),\n",
        "        'Inference_Time_ms': np.mean(time_list),\n",
        "        'FPS': 1000 / np.mean(time_list) if len(time_list) > 0 else 0\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Count number of parameters in model\"\"\"\n",
        "    total = 0\n",
        "    if hasattr(model, 'flownet'):\n",
        "        total += sum(p.numel() for p in model.flownet.parameters())\n",
        "    # Check for other submodules\n",
        "    for attr_name in dir(model):\n",
        "        attr = getattr(model, attr_name)\n",
        "        if isinstance(attr, torch.nn.Module) and attr_name != 'flownet':\n",
        "            total += sum(p.numel() for p in attr.parameters())\n",
        "    return total\n",
        "\n",
        "\n",
        "def select_best_sparsity(pruning_results, target_psnr_drop=0.3, baseline_psnr=35.292):\n",
        "    \"\"\"\n",
        "    Select best sparsity level based on quality-efficiency trade-off.\n",
        "\n",
        "    Args:\n",
        "        pruning_results: Dictionary mapping sparsity to results\n",
        "        target_psnr_drop: Maximum acceptable PSNR drop\n",
        "        baseline_psnr: Baseline PSNR to compare against\n",
        "\n",
        "    Returns:\n",
        "        best_sparsity: Selected sparsity level\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SPARSITY SELECTION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    acceptable_sparsities = []\n",
        "\n",
        "    for sparsity, results in sorted(pruning_results.items()):\n",
        "        psnr_drop = baseline_psnr - results['PSNR']\n",
        "        print(f\"Sparsity {sparsity:.1%}: PSNR={results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB), SSIM={results['SSIM']:.4f}\")\n",
        "\n",
        "        if psnr_drop <= target_psnr_drop:\n",
        "            acceptable_sparsities.append(sparsity)\n",
        "\n",
        "    if len(acceptable_sparsities) == 0:\n",
        "        print(f\"‚ö†Ô∏è  No sparsity level meets target drop of {target_psnr_drop} dB\")\n",
        "        print(\"    Selecting least aggressive option (30%)\")\n",
        "        return 0.3\n",
        "    else:\n",
        "        # Select highest acceptable sparsity (most compression)\n",
        "        best = max(acceptable_sparsities)\n",
        "        print(f\"‚úÖ Selected sparsity: {best:.1%}\")\n",
        "        return best\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN PRUNING PIPELINE\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PHASE 1: PRUNING EXPERIMENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Verify model is already loaded from previous cell\n",
        "if 'model' not in globals():\n",
        "    print(\"‚ö†Ô∏è  Model not found! Please run the first cell to load the model.\")\n",
        "    raise RuntimeError(\"Model not loaded. Run the baseline evaluation cell first.\")\n",
        "\n",
        "print(\"‚úÖ Using model from previous cell\")\n",
        "\n",
        "# Verify dataset path\n",
        "UCF_PATH = \"/content/drive/MyDrive/UCF-101/ucf101_interp_ours\"\n",
        "if not os.path.exists(UCF_PATH):\n",
        "    raise FileNotFoundError(f\"Dataset path not found: {UCF_PATH}\")\n",
        "print(f\"‚úÖ Dataset path verified: {UCF_PATH}\")\n",
        "\n",
        "# Get baseline PSNR (from your previous evaluation)\n",
        "baseline_psnr = 35.292  # From your full evaluation\n",
        "baseline_ssim = 0.9690\n",
        "\n",
        "print(f\"\\nBaseline metrics (from full evaluation):\")\n",
        "print(f\"  PSNR: {baseline_psnr:.3f} dB\")\n",
        "print(f\"  SSIM: {baseline_ssim:.4f}\")\n",
        "\n",
        "# Quick verification on subset\n",
        "print(\"\\nVerifying baseline on subset (20 samples)...\")\n",
        "baseline_quick = quick_evaluate(model, UCF_PATH, num_samples=20)\n",
        "print(f\"Baseline quick check - PSNR: {baseline_quick['PSNR']:.3f} dB, SSIM: {baseline_quick['SSIM']:.4f}\")\n",
        "\n",
        "# Step 1: Compute channel importance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 1: Computing Channel Importance\")\n",
        "print(\"=\"*60)\n",
        "importance_dict = compute_channel_importance(model.flownet)\n",
        "\n",
        "# Step 2: Test different sparsity levels\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: Testing Different Sparsity Levels\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sparsity_levels = [0.3, 0.5, 0.7]\n",
        "pruning_results = {}\n",
        "\n",
        "for sparsity in sparsity_levels:\n",
        "    print(f\"\\n{'‚îÄ'*60}\")\n",
        "    print(f\"Testing sparsity: {sparsity:.1%}\")\n",
        "    print(f\"{'‚îÄ'*60}\")\n",
        "\n",
        "    # Create pruning masks\n",
        "    prune_masks = global_channel_pruning(importance_dict, sparsity)\n",
        "\n",
        "    # Apply soft pruning\n",
        "    print(\"Applying pruning masks...\")\n",
        "    pruned_model = apply_soft_pruning(model, prune_masks)\n",
        "    pruned_model.device()  # Ensure on correct device\n",
        "\n",
        "    # Quick evaluation\n",
        "    print(f\"Evaluating pruned model (50 samples)...\")\n",
        "    results = quick_evaluate(pruned_model, UCF_PATH, num_samples=50)\n",
        "    pruning_results[sparsity] = results\n",
        "\n",
        "    # Calculate metrics\n",
        "    psnr_drop = baseline_psnr - results['PSNR']\n",
        "    ssim_drop = baseline_ssim - results['SSIM']\n",
        "    param_reduction = sparsity * 100\n",
        "    speedup = results['FPS'] / baseline_quick['FPS'] if baseline_quick['FPS'] > 0 else 1.0\n",
        "\n",
        "    print(f\"\\nüìä Results:\")\n",
        "    print(f\"  PSNR: {results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"  SSIM: {results['SSIM']:.4f} (drop: {ssim_drop:.4f})\")\n",
        "    print(f\"  Inference: {results['Inference_Time_ms']:.2f} ms ({results['FPS']:.1f} FPS)\")\n",
        "    print(f\"  Est. Param Reduction: ~{param_reduction:.0f}%\")\n",
        "    print(f\"  Speedup vs baseline: {speedup:.2f}x\")\n",
        "\n",
        "    # Clear GPU cache\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Delete pruned model to free memory\n",
        "    del pruned_model\n",
        "\n",
        "# Step 3: Select best sparsity\n",
        "best_sparsity = select_best_sparsity(pruning_results, target_psnr_drop=0.5, baseline_psnr=baseline_psnr)\n",
        "\n",
        "# Step 4: Create final pruned model\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"STEP 3: Creating Final Pruned Model\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Selected sparsity: {best_sparsity:.1%}\")\n",
        "\n",
        "final_prune_masks = global_channel_pruning(importance_dict, best_sparsity)\n",
        "pruned_model_final = apply_soft_pruning(model, final_prune_masks)\n",
        "pruned_model_final.device()\n",
        "\n",
        "# Step 5: Comprehensive evaluation\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"STEP 4: Comprehensive Evaluation\")\n",
        "print(f\"{'='*60}\")\n",
        "print(\"Evaluating on FULL UCF-101 dataset (379 sequences)...\")\n",
        "print(\"‚è±Ô∏è  This may take 5-10 minutes...\")\n",
        "\n",
        "final_results = quick_evaluate(pruned_model_final, UCF_PATH, num_samples=379)\n",
        "\n",
        "# Step 6: Print final comparison\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FINAL RESULTS\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "print(f\"\\nüìä Baseline Model:\")\n",
        "print(f\"  PSNR: {baseline_psnr:.3f} dB\")\n",
        "print(f\"  SSIM: {baseline_ssim:.4f}\")\n",
        "print(f\"  Parameters: {count_parameters(model):,} ({count_parameters(model)/1e6:.2f}M)\")\n",
        "\n",
        "print(f\"\\nüìä Pruned Model (Sparsity: {best_sparsity:.1%}):\")\n",
        "print(f\"  PSNR: {final_results['PSNR']:.3f} dB (Œî: {baseline_psnr - final_results['PSNR']:.3f} dB)\")\n",
        "print(f\"  SSIM: {final_results['SSIM']:.4f} (Œî: {baseline_ssim - final_results['SSIM']:.4f})\")\n",
        "print(f\"  Inference Time: {final_results['Inference_Time_ms']:.2f} ms\")\n",
        "print(f\"  FPS: {final_results['FPS']:.1f}\")\n",
        "print(f\"  Est. Param Reduction: ~{best_sparsity*100:.0f}%\")\n",
        "\n",
        "# Step 7: Save results\n",
        "results_summary = {\n",
        "    'baseline': {\n",
        "        'PSNR': baseline_psnr,\n",
        "        'SSIM': baseline_ssim,\n",
        "        'Parameters': count_parameters(model)\n",
        "    },\n",
        "    'pruned': {\n",
        "        'sparsity': best_sparsity,\n",
        "        'PSNR': final_results['PSNR'],\n",
        "        'SSIM': final_results['SSIM'],\n",
        "        'Inference_Time_ms': final_results['Inference_Time_ms'],\n",
        "        'FPS': final_results['FPS'],\n",
        "        'PSNR_drop': baseline_psnr - final_results['PSNR'],\n",
        "        'SSIM_drop': baseline_ssim - final_results['SSIM']\n",
        "    },\n",
        "    'all_sparsity_experiments': {k: v for k, v in pruning_results.items()}\n",
        "}\n",
        "\n",
        "# Save to file\n",
        "with open('/content/pruning_results.json', 'w') as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "print(f\"\\nüíæ Results saved to '/content/pruning_results.json'\")\n",
        "\n",
        "# Save pruned model state\n",
        "torch.save({\n",
        "    'flownet_state_dict': pruned_model_final.flownet.state_dict(),\n",
        "    'sparsity': best_sparsity,\n",
        "    'prune_masks': {k: v.numpy() for k, v in final_prune_masks.items()},\n",
        "    'results': final_results\n",
        "}, '/content/pruned_model_checkpoint.pth')\n",
        "\n",
        "print(f\"üíæ Pruned model saved to '/content/pruned_model_checkpoint.pth'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ PRUNING PHASE COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nNext steps:\")\n",
        "print(\"  1. Review results in 'pruning_results.json'\")\n",
        "print(\"  2. Proceed to fine-tuning (if PSNR drop > 0.3 dB)\")\n",
        "print(\"  3. Or proceed to quantization phase\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# COMPLETE CORRECTED PRUNING IMPLEMENTATION\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import json\n",
        "\n",
        "# ============================================================\n",
        "# CORRECTED HELPER FUNCTIONS\n",
        "# ============================================================\n",
        "\n",
        "def compute_channel_importance_v2(module, layer_types=[nn.Conv2d]):\n",
        "    \"\"\"\n",
        "    Compute L1-norm importance for each channel (VERIFIED CORRECT)\n",
        "    \"\"\"\n",
        "    importance_dict = {}\n",
        "\n",
        "    for name, layer in module.named_modules():\n",
        "        if isinstance(layer, tuple(layer_types)):\n",
        "            weight = layer.weight.data\n",
        "            # L1 norm per output channel: sum over [in_channels, H, W]\n",
        "            importance = torch.norm(weight.view(weight.size(0), -1), p=1, dim=1)\n",
        "            importance_dict[name] = importance.cpu()\n",
        "\n",
        "    print(f\"‚úÖ Analyzed {len(importance_dict)} convolutional layers\")\n",
        "\n",
        "    # Debug statistics\n",
        "    all_imp = torch.cat([imp for imp in importance_dict.values()])\n",
        "    print(f\"   Importance range: [{all_imp.min():.2f}, {all_imp.max():.2f}], Mean: {all_imp.mean():.2f}\")\n",
        "\n",
        "    return importance_dict\n",
        "\n",
        "\n",
        "def global_channel_pruning_v2(importance_dict, sparsity=0.5):\n",
        "    \"\"\"\n",
        "    CORRECTED: Prune channels with SMALLEST importance (least important)\n",
        "\n",
        "    Args:\n",
        "        importance_dict: Channel importance scores\n",
        "        sparsity: Fraction of channels to REMOVE (0-1)\n",
        "\n",
        "    Returns:\n",
        "        prune_masks: Boolean masks (True = KEEP, False = PRUNE)\n",
        "    \"\"\"\n",
        "    # Flatten all importance scores\n",
        "    all_importance = torch.cat([imp for imp in importance_dict.values()])\n",
        "    total_channels = len(all_importance)\n",
        "\n",
        "    # Calculate how many to KEEP\n",
        "    num_to_keep = int(total_channels * (1 - sparsity))\n",
        "\n",
        "    # Sort importance in DESCENDING order and get threshold\n",
        "    # Channels with importance >= threshold will be KEPT\n",
        "    sorted_importance = torch.sort(all_importance, descending=True)[0]\n",
        "    threshold = sorted_importance[num_to_keep - 1] if num_to_keep > 0 else sorted_importance[-1]\n",
        "\n",
        "    print(f\"   Sparsity: {sparsity:.1%}\")\n",
        "    print(f\"   Total channels: {total_channels}\")\n",
        "    print(f\"   Channels to keep: {num_to_keep}\")\n",
        "    print(f\"   Threshold: {threshold:.6f}\")\n",
        "    print(f\"   Logic: KEEP channels with importance >= {threshold:.6f}\")\n",
        "\n",
        "    # Create masks: True = KEEP, False = PRUNE\n",
        "    prune_masks = {}\n",
        "    total_kept = 0\n",
        "\n",
        "    for name, importance in importance_dict.items():\n",
        "        # CORRECTED: Keep channels with importance >= threshold\n",
        "        mask = (importance >= threshold)\n",
        "        prune_masks[name] = mask\n",
        "        total_kept += mask.sum().item()\n",
        "\n",
        "    actual_sparsity = 1 - (total_kept / total_channels)\n",
        "    actual_kept_pct = (total_kept / total_channels) * 100\n",
        "\n",
        "    print(f\"   Result: {total_kept}/{total_channels} channels kept ({actual_kept_pct:.1f}%)\")\n",
        "    print(f\"   Actual sparsity: {actual_sparsity:.1%}\")\n",
        "\n",
        "    return prune_masks\n",
        "\n",
        "\n",
        "def apply_soft_pruning_v2(model, prune_masks):\n",
        "    \"\"\"\n",
        "    Apply soft pruning by zeroing out weights (VERIFIED CORRECT)\n",
        "    \"\"\"\n",
        "    from model.RIFE import Model as RIFEModel\n",
        "\n",
        "    # Create fresh model instance\n",
        "    pruned_model = RIFEModel()\n",
        "    pruned_model.load_model('train_log')\n",
        "    pruned_model.eval()\n",
        "\n",
        "    # Apply masks\n",
        "    total_channels = 0\n",
        "    zeroed_channels = 0\n",
        "    layers_modified = 0\n",
        "\n",
        "    for name, module in pruned_model.flownet.named_modules():\n",
        "        if name in prune_masks:\n",
        "            mask = prune_masks[name]\n",
        "            device = next(module.parameters()).device\n",
        "\n",
        "            # Create weight mask: expand to [out_ch, in_ch, H, W]\n",
        "            weight_mask = mask.view(-1, 1, 1, 1).expand_as(module.weight).to(device)\n",
        "\n",
        "            # Apply mask: multiply weights by mask (zeros out pruned channels)\n",
        "            module.weight.data *= weight_mask\n",
        "\n",
        "            # Apply to bias if exists\n",
        "            if module.bias is not None:\n",
        "                bias_mask = mask.to(device)\n",
        "                module.bias.data *= bias_mask\n",
        "\n",
        "            # Track statistics\n",
        "            zeroed = (~mask).sum().item()\n",
        "            total = len(mask)\n",
        "            zeroed_channels += zeroed\n",
        "            total_channels += total\n",
        "            layers_modified += 1\n",
        "\n",
        "    print(f\"   Applied masks to {layers_modified} layers\")\n",
        "    print(f\"   Zeroed {zeroed_channels}/{total_channels} channels ({zeroed_channels/total_channels*100:.1f}%)\")\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "\n",
        "def quick_evaluate_v2(model, dataset_path, num_samples=50):\n",
        "    \"\"\"\n",
        "    Quick evaluation (same as before, just renamed for consistency)\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    import math\n",
        "    from model.pytorch_msssim import ssim_matlab\n",
        "\n",
        "    model.eval()\n",
        "    device = next(model.flownet.parameters()).device\n",
        "\n",
        "    dirs = os.listdir(dataset_path)[:num_samples]\n",
        "    psnr_list, ssim_list, time_list = [], [], []\n",
        "\n",
        "    for d in tqdm(dirs, desc=\"Evaluating\", leave=False):\n",
        "        img0_path = os.path.join(dataset_path, d, 'frame_00.png')\n",
        "        img1_path = os.path.join(dataset_path, d, 'frame_02.png')\n",
        "        gt_path = os.path.join(dataset_path, d, 'frame_01_gt.png')\n",
        "\n",
        "        if not all(map(os.path.exists, [img0_path, img1_path, gt_path])):\n",
        "            continue\n",
        "\n",
        "        img0 = torch.tensor(cv2.imread(img0_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "        img1 = torch.tensor(cv2.imread(img1_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "        gt = torch.tensor(cv2.imread(gt_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        start_time = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model.inference(img0, img1)[0]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        time_list.append((time.time() - start_time) * 1000)\n",
        "\n",
        "        ssim_val = ssim_matlab(gt, torch.round(pred*255).unsqueeze(0)/255).detach().cpu().numpy()\n",
        "        ssim_list.append(float(ssim_val))\n",
        "\n",
        "        out = pred.detach().cpu().numpy().transpose(1,2,0)\n",
        "        out = np.round(out*255)/255.\n",
        "        gt_np = gt[0].cpu().numpy().transpose(1,2,0)\n",
        "        mse = ((gt_np - out)**2).mean()\n",
        "        psnr = -10 * math.log10(mse + 1e-8)\n",
        "        psnr_list.append(psnr)\n",
        "\n",
        "    return {\n",
        "        'PSNR': np.mean(psnr_list),\n",
        "        'SSIM': np.mean(ssim_list),\n",
        "        'Inference_Time_ms': np.mean(time_list),\n",
        "        'FPS': 1000 / np.mean(time_list) if len(time_list) > 0 else 0\n",
        "    }\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: VERIFY THE FIX WITH DIAGNOSTIC\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: DIAGNOSTIC - COMPARE OLD VS NEW PRUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if 'model' not in globals():\n",
        "    raise RuntimeError(\"Model not found. Run baseline cell first.\")\n",
        "\n",
        "UCF_PATH = \"/content/drive/MyDrive/UCF-101/ucf101_interp_ours\"\n",
        "baseline_psnr = 35.292\n",
        "baseline_ssim = 0.9690\n",
        "\n",
        "# Compute importance with new function\n",
        "print(\"\\nComputing channel importance...\")\n",
        "importance_dict_v2 = compute_channel_importance_v2(model.flownet)\n",
        "\n",
        "# Test both methods on same sparsity\n",
        "sparsity_test = 0.3\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"COMPARING METHODS AT {sparsity_test:.0%} SPARSITY\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Old method (from your previous run - we know it gives 25.699 dB)\n",
        "print(\"\\nüî¥ OLD METHOD (inverted logic):\")\n",
        "masks_old = global_channel_pruning(importance_dict, sparsity_test)  # Your old function\n",
        "model_old = apply_soft_pruning(model, masks_old)\n",
        "model_old.device()\n",
        "results_old = quick_evaluate(model_old, UCF_PATH, num_samples=20)\n",
        "print(f\"   PSNR: {results_old['PSNR']:.3f} dB\")\n",
        "print(f\"   SSIM: {results_old['SSIM']:.4f}\")\n",
        "\n",
        "# New corrected method\n",
        "print(\"\\n‚úÖ NEW METHOD (corrected logic):\")\n",
        "masks_new = global_channel_pruning_v2(importance_dict_v2, sparsity_test)\n",
        "model_new = apply_soft_pruning_v2(model, masks_new)\n",
        "model_new.device()\n",
        "results_new = quick_evaluate_v2(model_new, UCF_PATH, num_samples=20)\n",
        "print(f\"   PSNR: {results_new['PSNR']:.3f} dB\")\n",
        "print(f\"   SSIM: {results_new['SSIM']:.4f}\")\n",
        "\n",
        "# Comparison\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"DIAGNOSTIC RESULT:\")\n",
        "print(f\"{'='*60}\")\n",
        "improvement = results_new['PSNR'] - results_old['PSNR']\n",
        "if improvement > 5.0:\n",
        "    print(f\"‚úÖ MAJOR IMPROVEMENT: +{improvement:.2f} dB\")\n",
        "    print(f\"   Old logic was definitely inverted!\")\n",
        "    print(f\"   Proceeding with corrected pruning...\")\n",
        "elif improvement > 1.0:\n",
        "    print(f\"‚úÖ IMPROVEMENT: +{improvement:.2f} dB\")\n",
        "    print(f\"   New logic is better\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  MINIMAL DIFFERENCE: {improvement:.2f} dB\")\n",
        "    print(f\"   Issue might be elsewhere\")\n",
        "\n",
        "# Cleanup\n",
        "del model_old, model_new\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: RUN CORRECTED PRUNING EXPERIMENTS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: CORRECTED PRUNING EXPERIMENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sparsity_levels = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "pruning_results_v2 = {}\n",
        "\n",
        "for sparsity in sparsity_levels:\n",
        "    print(f\"\\n{'‚îÄ'*60}\")\n",
        "    print(f\"Testing sparsity: {sparsity:.1%}\")\n",
        "    print(f\"{'‚îÄ'*60}\")\n",
        "\n",
        "    # Create masks with corrected method\n",
        "    prune_masks = global_channel_pruning_v2(importance_dict_v2, sparsity)\n",
        "\n",
        "    # Apply pruning\n",
        "    pruned_model = apply_soft_pruning_v2(model, prune_masks)\n",
        "    pruned_model.device()\n",
        "\n",
        "    # Evaluate\n",
        "    print(f\"\\nEvaluating on 50 samples...\")\n",
        "    results = quick_evaluate_v2(pruned_model, UCF_PATH, num_samples=50)\n",
        "    pruning_results_v2[sparsity] = results\n",
        "\n",
        "    # Calculate metrics\n",
        "    psnr_drop = baseline_psnr - results['PSNR']\n",
        "    ssim_drop = baseline_ssim - results['SSIM']\n",
        "\n",
        "    print(f\"\\nüìä Results:\")\n",
        "    print(f\"   PSNR: {results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"   SSIM: {results['SSIM']:.4f} (drop: {ssim_drop:.4f})\")\n",
        "    print(f\"   Inference: {results['Inference_Time_ms']:.2f} ms ({results['FPS']:.1f} FPS)\")\n",
        "\n",
        "    # Clear memory\n",
        "    del pruned_model\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: SELECT OPTIMAL SPARSITY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: SELECTING OPTIMAL SPARSITY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n{'Sparsity':<10} {'PSNR':<10} {'Drop':<10} {'SSIM':<10} {'Status':<15}\")\n",
        "print(\"‚îÄ\"*60)\n",
        "\n",
        "acceptable = {}\n",
        "for sparsity in sorted(pruning_results_v2.keys()):\n",
        "    results = pruning_results_v2[sparsity]\n",
        "    psnr_drop = baseline_psnr - results['PSNR']\n",
        "\n",
        "    if psnr_drop <= 0.5:\n",
        "        status = \"‚úÖ Excellent\"\n",
        "        acceptable[sparsity] = results\n",
        "    elif psnr_drop <= 1.0:\n",
        "        status = \"‚úÖ Good\"\n",
        "        acceptable[sparsity] = results\n",
        "    elif psnr_drop <= 1.5:\n",
        "        status = \"‚ö†Ô∏è  Marginal\"\n",
        "    else:\n",
        "        status = \"‚ùå Too high\"\n",
        "\n",
        "    print(f\"{sparsity:<10.1%} {results['PSNR']:<10.3f} {psnr_drop:<10.3f} {results['SSIM']:<10.4f} {status:<15}\")\n",
        "\n",
        "print(\"\\n\" + \"‚îÄ\"*60)\n",
        "\n",
        "if len(acceptable) > 0:\n",
        "    # Choose highest acceptable sparsity (most compression)\n",
        "    best_sparsity = max(acceptable.keys())\n",
        "    best_results = acceptable[best_sparsity]\n",
        "    psnr_drop = baseline_psnr - best_results['PSNR']\n",
        "\n",
        "    print(f\"‚úÖ SELECTED: {best_sparsity:.1%} sparsity\")\n",
        "    print(f\"   PSNR: {best_results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"   SSIM: {best_results['SSIM']:.4f}\")\n",
        "    print(f\"   Quality: {'Excellent' if psnr_drop <= 0.5 else 'Good'}\")\n",
        "else:\n",
        "    # Use minimum sparsity\n",
        "    best_sparsity = min(pruning_results_v2.keys())\n",
        "    best_results = pruning_results_v2[best_sparsity]\n",
        "    psnr_drop = baseline_psnr - best_results['PSNR']\n",
        "\n",
        "    print(f\"‚ö†Ô∏è  SELECTED: {best_sparsity:.1%} sparsity (minimum)\")\n",
        "    print(f\"   PSNR: {best_results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"   Note: All sparsity levels had high degradation\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: FINAL EVALUATION ON FULL DATASET\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: FULL EVALUATION ON UCF-101\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nCreating final pruned model ({best_sparsity:.1%} sparsity)...\")\n",
        "final_masks = global_channel_pruning_v2(importance_dict_v2, best_sparsity)\n",
        "final_pruned_model = apply_soft_pruning_v2(model, final_masks)\n",
        "final_pruned_model.device()\n",
        "\n",
        "print(f\"\\nEvaluating on full UCF-101 dataset (379 sequences)...\")\n",
        "print(\"‚è±Ô∏è  This will take 5-10 minutes...\")\n",
        "\n",
        "final_results = quick_evaluate_v2(final_pruned_model, UCF_PATH, num_samples=379)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: FINAL REPORT\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULTS - CORRECTED PRUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nüìä BASELINE MODEL:\")\n",
        "print(f\"   PSNR: {baseline_psnr:.3f} dB\")\n",
        "print(f\"   SSIM: {baseline_ssim:.4f}\")\n",
        "print(f\"   Parameters: {count_parameters(model):,} ({count_parameters(model)/1e6:.2f}M)\")\n",
        "\n",
        "print(f\"\\nüìä PRUNED MODEL (Sparsity: {best_sparsity:.1%}):\")\n",
        "psnr_drop_final = baseline_psnr - final_results['PSNR']\n",
        "ssim_drop_final = baseline_ssim - final_results['SSIM']\n",
        "\n",
        "print(f\"   PSNR: {final_results['PSNR']:.3f} dB (Œî: {psnr_drop_final:.3f} dB)\")\n",
        "print(f\"   SSIM: {final_results['SSIM']:.4f} (Œî: {ssim_drop_final:.4f})\")\n",
        "print(f\"   Inference: {final_results['Inference_Time_ms']:.2f} ms\")\n",
        "print(f\"   FPS: {final_results['FPS']:.1f}\")\n",
        "print(f\"   Est. Param Reduction: ~{best_sparsity*100:.0f}%\")\n",
        "\n",
        "# Quality assessment\n",
        "if psnr_drop_final <= 0.5:\n",
        "    quality_verdict = \"‚úÖ EXCELLENT - No fine-tuning needed\"\n",
        "elif psnr_drop_final <= 1.0:\n",
        "    quality_verdict = \"‚úÖ GOOD - Optional fine-tuning\"\n",
        "elif psnr_drop_final <= 2.0:\n",
        "    quality_verdict = \"‚ö†Ô∏è  ACCEPTABLE - Fine-tuning recommended\"\n",
        "else:\n",
        "    quality_verdict = \"‚ùå POOR - Fine-tuning required\"\n",
        "\n",
        "print(f\"\\n{quality_verdict}\")\n",
        "\n",
        "# Save results\n",
        "results_summary = {\n",
        "    'baseline': {\n",
        "        'PSNR': baseline_psnr,\n",
        "        'SSIM': baseline_ssim,\n",
        "        'Parameters': count_parameters(model)\n",
        "    },\n",
        "    'pruned_corrected': {\n",
        "        'sparsity': best_sparsity,\n",
        "        'PSNR': final_results['PSNR'],\n",
        "        'SSIM': final_results['SSIM'],\n",
        "        'PSNR_drop': psnr_drop_final,\n",
        "        'SSIM_drop': ssim_drop_final,\n",
        "        'Inference_Time_ms': final_results['Inference_Time_ms'],\n",
        "        'FPS': final_results['FPS']\n",
        "    },\n",
        "    'all_experiments': {str(k): v for k, v in pruning_results_v2.items()}\n",
        "}\n",
        "\n",
        "with open('/content/pruning_results_corrected.json', 'w') as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "print(f\"\\nüíæ Results saved to '/content/pruning_results_corrected.json'\")\n",
        "\n",
        "# Save model\n",
        "torch.save({\n",
        "    'flownet_state_dict': final_pruned_model.flownet.state_dict(),\n",
        "    'sparsity': best_sparsity,\n",
        "    'masks': {k: v.numpy() for k, v in final_masks.items()},\n",
        "    'results': final_results\n",
        "}, '/content/pruned_model_corrected.pth')\n",
        "\n",
        "print(f\"üíæ Model saved to '/content/pruned_model_corrected.pth'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ CORRECTED PRUNING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Next steps recommendation\n",
        "print(\"\\nüìã NEXT STEPS:\")\n",
        "if psnr_drop_final <= 1.0:\n",
        "    print(\"   1. ‚úÖ Proceed to quantization (quality is good)\")\n",
        "    print(\"   2. Optional: Fine-tune for further improvement\")\n",
        "    print(\"   3. Implement video processing pipeline\")\n",
        "elif psnr_drop_final <= 2.0:\n",
        "    print(\"   1. ‚ö†Ô∏è  Fine-tune the pruned model (recommended)\")\n",
        "    print(\"   2. Then proceed to quantization\")\n",
        "    print(\"   3. Implement video processing pipeline\")\n",
        "else:\n",
        "    print(\"   1. ‚ùå Fine-tune the pruned model (required)\")\n",
        "    print(\"   2. Re-evaluate after fine-tuning\")\n",
        "    print(\"   3. Then consider quantization\")\n",
        "\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbjwGv2HcFZq",
        "outputId": "7b5c8aff-3cb4-4054-8418-55de3211ea1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: DIAGNOSTIC - COMPARE OLD VS NEW PRUNING\n",
            "============================================================\n",
            "\n",
            "Computing channel importance...\n",
            "‚úÖ Analyzed 57 convolutional layers\n",
            "   Importance range: [1.89, 188.22], Mean: 73.84\n",
            "\n",
            "============================================================\n",
            "COMPARING METHODS AT 30% SPARSITY\n",
            "============================================================\n",
            "\n",
            "üî¥ OLD METHOD (inverted logic):\n",
            "Sparsity: 30.0%, Threshold: 40.140980\n",
            "Actual pruning: 2058/6858 channels (30.0%)\n",
            "Quick evaluation on 20 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PSNR: 25.699 dB\n",
            "   SSIM: 0.8843\n",
            "\n",
            "‚úÖ NEW METHOD (corrected logic):\n",
            "   Sparsity: 30.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 4800\n",
            "   Threshold: 40.152420\n",
            "   Logic: KEEP channels with importance >= 40.152420\n",
            "   Result: 4800/6858 channels kept (70.0%)\n",
            "   Actual sparsity: 30.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 2058/6858 channels (30.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PSNR: 25.699 dB\n",
            "   SSIM: 0.8843\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC RESULT:\n",
            "============================================================\n",
            "‚ö†Ô∏è  MINIMAL DIFFERENCE: -0.00 dB\n",
            "   Issue might be elsewhere\n",
            "\n",
            "============================================================\n",
            "STEP 2: CORRECTED PRUNING EXPERIMENTS\n",
            "============================================================\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 10.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 10.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 6172\n",
            "   Threshold: 21.201897\n",
            "   Logic: KEEP channels with importance >= 21.201897\n",
            "   Result: 6172/6858 channels kept (90.0%)\n",
            "   Actual sparsity: 10.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 686/6858 channels (10.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 19.370 dB (drop: 15.922 dB)\n",
            "   SSIM: 0.7133 (drop: 0.2557)\n",
            "   Inference: 9.91 ms (100.9 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 20.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 20.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 5486\n",
            "   Threshold: 30.632299\n",
            "   Logic: KEEP channels with importance >= 30.632299\n",
            "   Result: 5486/6858 channels kept (80.0%)\n",
            "   Actual sparsity: 20.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 1372/6858 channels (20.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 19.840 dB (drop: 15.452 dB)\n",
            "   SSIM: 0.7401 (drop: 0.2289)\n",
            "   Inference: 10.17 ms (98.3 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 30.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 30.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 4800\n",
            "   Threshold: 40.152420\n",
            "   Logic: KEEP channels with importance >= 40.152420\n",
            "   Result: 4800/6858 channels kept (70.0%)\n",
            "   Actual sparsity: 30.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 2058/6858 channels (30.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 25.319 dB (drop: 9.973 dB)\n",
            "   SSIM: 0.8772 (drop: 0.0918)\n",
            "   Inference: 12.38 ms (80.8 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 40.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 40.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 4114\n",
            "   Threshold: 50.451553\n",
            "   Logic: KEEP channels with importance >= 50.451553\n",
            "   Result: 4114/6858 channels kept (60.0%)\n",
            "   Actual sparsity: 40.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 2744/6858 channels (40.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 31.874 dB (drop: 3.418 dB)\n",
            "   SSIM: 0.9603 (drop: 0.0087)\n",
            "   Inference: 10.10 ms (99.0 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 50.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 50.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 3429\n",
            "   Threshold: 73.872589\n",
            "   Logic: KEEP channels with importance >= 73.872589\n",
            "   Result: 3429/6858 channels kept (50.0%)\n",
            "   Actual sparsity: 50.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 3429/6858 channels (50.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 32.361 dB (drop: 2.931 dB)\n",
            "   SSIM: 0.9622 (drop: 0.0068)\n",
            "   Inference: 10.05 ms (99.5 FPS)\n",
            "\n",
            "============================================================\n",
            "STEP 3: SELECTING OPTIMAL SPARSITY\n",
            "============================================================\n",
            "\n",
            "Sparsity   PSNR       Drop       SSIM       Status         \n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "10.0%      19.370     15.922     0.7133     ‚ùå Too high     \n",
            "20.0%      19.840     15.452     0.7401     ‚ùå Too high     \n",
            "30.0%      25.319     9.973      0.8772     ‚ùå Too high     \n",
            "40.0%      31.874     3.418      0.9603     ‚ùå Too high     \n",
            "50.0%      32.361     2.931      0.9622     ‚ùå Too high     \n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "‚ö†Ô∏è  SELECTED: 10.0% sparsity (minimum)\n",
            "   PSNR: 19.370 dB (drop: 15.922 dB)\n",
            "   Note: All sparsity levels had high degradation\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "STEP 4: FULL EVALUATION ON UCF-101\n",
            "============================================================\n",
            "\n",
            "Creating final pruned model (10.0% sparsity)...\n",
            "   Sparsity: 10.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 6172\n",
            "   Threshold: 21.201897\n",
            "   Logic: KEEP channels with importance >= 21.201897\n",
            "   Result: 6172/6858 channels kept (90.0%)\n",
            "   Actual sparsity: 10.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 686/6858 channels (10.0%)\n",
            "\n",
            "Evaluating on full UCF-101 dataset (379 sequences)...\n",
            "‚è±Ô∏è  This will take 5-10 minutes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL RESULTS - CORRECTED PRUNING\n",
            "============================================================\n",
            "\n",
            "üìä BASELINE MODEL:\n",
            "   PSNR: 35.292 dB\n",
            "   SSIM: 0.9690\n",
            "   Parameters: 10,708,215 (10.71M)\n",
            "\n",
            "üìä PRUNED MODEL (Sparsity: 10.0%):\n",
            "   PSNR: 18.946 dB (Œî: 16.346 dB)\n",
            "   SSIM: 0.6772 (Œî: 0.2918)\n",
            "   Inference: 10.69 ms\n",
            "   FPS: 93.6\n",
            "   Est. Param Reduction: ~10%\n",
            "\n",
            "‚ùå POOR - Fine-tuning required\n",
            "\n",
            "üíæ Results saved to '/content/pruning_results_corrected.json'\n",
            "üíæ Model saved to '/content/pruned_model_corrected.pth'\n",
            "\n",
            "============================================================\n",
            "‚úÖ CORRECTED PRUNING COMPLETE!\n",
            "============================================================\n",
            "\n",
            "üìã NEXT STEPS:\n",
            "   1. ‚ùå Fine-tune the pruned model (required)\n",
            "   2. Re-evaluate after fine-tuning\n",
            "   3. Then consider quantization\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# DIAGNOSTIC: Analyze Layer-wise Pruning Distribution\n",
        "# ============================================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze_pruning_distribution(importance_dict, sparsity_levels=[0.1, 0.3, 0.5]):\n",
        "    \"\"\"\n",
        "    Analyze which layers get pruned at different sparsity levels\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"ANALYZING LAYER-WISE PRUNING DISTRIBUTION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Get all importance scores\n",
        "    all_importance = torch.cat([imp for imp in importance_dict.values()])\n",
        "    layer_names = list(importance_dict.keys())\n",
        "\n",
        "    for sparsity in sparsity_levels:\n",
        "        print(f\"\\n{'‚îÄ'*60}\")\n",
        "        print(f\"Sparsity: {sparsity:.1%}\")\n",
        "        print(f\"{'‚îÄ'*60}\")\n",
        "\n",
        "        # Calculate threshold\n",
        "        num_to_keep = int(len(all_importance) * (1 - sparsity))\n",
        "        threshold = torch.sort(all_importance, descending=True)[0][num_to_keep - 1]\n",
        "\n",
        "        print(f\"Threshold: {threshold:.2f}\")\n",
        "        print(f\"\\nLayer-wise pruning:\")\n",
        "        print(f\"{'Layer':<40} {'Channels':<12} {'Pruned':<12} {'Prune %':<10}\")\n",
        "        print(\"‚îÄ\"*60)\n",
        "\n",
        "        for name, importance in importance_dict.items():\n",
        "            total_channels = len(importance)\n",
        "            pruned_channels = (importance < threshold).sum().item()\n",
        "            prune_pct = (pruned_channels / total_channels) * 100\n",
        "\n",
        "            # Highlight if heavily pruned\n",
        "            indicator = \"‚ö†Ô∏è \" if prune_pct > 50 else \"  \"\n",
        "\n",
        "            # Check if it's an early block\n",
        "            is_early = any(x in name for x in ['block0', 'down0', 'conv0', 'encoder.0', 'encoder.1'])\n",
        "            layer_label = f\"{name:<38}\"\n",
        "            if is_early:\n",
        "                layer_label = f\"üî¥ {name:<36}\"  # Mark early layers\n",
        "\n",
        "            print(f\"{indicator}{layer_label} {total_channels:<12} {pruned_channels:<12} {prune_pct:<10.1f}%\")\n",
        "\n",
        "        print()\n",
        "\n",
        "# Run the analysis\n",
        "print(\"\\nAnalyzing pruning distribution across layers...\\n\")\n",
        "analyze_pruning_distribution(importance_dict_v2, sparsity_levels=[0.1, 0.3, 0.5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH_cUkaTh3Bo",
        "outputId": "a57c9286-63d8-45ba-8921-074a5c240f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Analyzing pruning distribution across layers...\n",
            "\n",
            "============================================================\n",
            "ANALYZING LAYER-WISE PRUNING DISTRIBUTION\n",
            "============================================================\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Sparsity: 10.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Threshold: 21.20\n",
            "\n",
            "Layer-wise pruning:\n",
            "Layer                                    Channels     Pruned       Prune %   \n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "‚ö†Ô∏è üî¥ block0.conv0.0.0                     120          120          100.0     %\n",
            "  üî¥ block0.conv0.1.0                     240          0            0.0       %\n",
            "  üî¥ block0.convblock.0.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.1.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.2.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.3.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.4.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.5.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.6.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.7.0                 240          0            0.0       %\n",
            "‚ö†Ô∏è üî¥ block1.conv0.0.0                     75           75           100.0     %\n",
            "  üî¥ block1.conv0.1.0                     150          1            0.7       %\n",
            "  block1.convblock.0.0                   150          0            0.0       %\n",
            "  block1.convblock.1.0                   150          0            0.0       %\n",
            "  block1.convblock.2.0                   150          0            0.0       %\n",
            "  block1.convblock.3.0                   150          0            0.0       %\n",
            "  block1.convblock.4.0                   150          0            0.0       %\n",
            "  block1.convblock.5.0                   150          0            0.0       %\n",
            "  block1.convblock.6.0                   150          0            0.0       %\n",
            "  block1.convblock.7.0                   150          0            0.0       %\n",
            "‚ö†Ô∏è üî¥ block2.conv0.0.0                     45           45           100.0     %\n",
            "‚ö†Ô∏è üî¥ block2.conv0.1.0                     90           74           82.2      %\n",
            "  block2.convblock.0.0                   90           2            2.2       %\n",
            "  block2.convblock.1.0                   90           1            1.1       %\n",
            "  block2.convblock.2.0                   90           1            1.1       %\n",
            "  block2.convblock.3.0                   90           0            0.0       %\n",
            "  block2.convblock.4.0                   90           0            0.0       %\n",
            "  block2.convblock.5.0                   90           0            0.0       %\n",
            "  block2.convblock.6.0                   90           0            0.0       %\n",
            "  block2.convblock.7.0                   90           8            8.9       %\n",
            "‚ö†Ô∏è üî¥ block_tea.conv0.0.0                  45           45           100.0     %\n",
            "‚ö†Ô∏è üî¥ block_tea.conv0.1.0                  90           90           100.0     %\n",
            "  block_tea.convblock.0.0                90           5            5.6       %\n",
            "  block_tea.convblock.1.0                90           7            7.8       %\n",
            "  block_tea.convblock.2.0                90           13           14.4      %\n",
            "  block_tea.convblock.3.0                90           1            1.1       %\n",
            "  block_tea.convblock.4.0                90           0            0.0       %\n",
            "  block_tea.convblock.5.0                90           0            0.0       %\n",
            "  block_tea.convblock.6.0                90           3            3.3       %\n",
            "  block_tea.convblock.7.0                90           21           23.3      %\n",
            "‚ö†Ô∏è contextnet.conv1.conv1.0               16           16           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv1.conv2.0               16           16           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv2.conv1.0               32           32           100.0     %\n",
            "  contextnet.conv2.conv2.0               32           16           50.0      %\n",
            "  contextnet.conv3.conv1.0               64           26           40.6      %\n",
            "  contextnet.conv3.conv2.0               64           0            0.0       %\n",
            "  contextnet.conv4.conv1.0               128          0            0.0       %\n",
            "  contextnet.conv4.conv2.0               128          0            0.0       %\n",
            "‚ö†Ô∏è üî¥ unet.down0.conv1.0                   32           32           100.0     %\n",
            "‚ö†Ô∏è üî¥ unet.down0.conv2.0                   32           32           100.0     %\n",
            "  unet.down1.conv1.0                     64           1            1.6       %\n",
            "  unet.down1.conv2.0                     64           0            0.0       %\n",
            "  unet.down2.conv1.0                     128          0            0.0       %\n",
            "  unet.down2.conv2.0                     128          0            0.0       %\n",
            "  unet.down3.conv1.0                     256          0            0.0       %\n",
            "  unet.down3.conv2.0                     256          0            0.0       %\n",
            "‚ö†Ô∏è unet.conv                              3            3            100.0     %\n",
            "\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Sparsity: 30.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Threshold: 40.15\n",
            "\n",
            "Layer-wise pruning:\n",
            "Layer                                    Channels     Pruned       Prune %   \n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "‚ö†Ô∏è üî¥ block0.conv0.0.0                     120          120          100.0     %\n",
            "  üî¥ block0.conv0.1.0                     240          96           40.0      %\n",
            "  üî¥ block0.convblock.0.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.1.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.2.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.3.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.4.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.5.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.6.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.7.0                 240          0            0.0       %\n",
            "‚ö†Ô∏è üî¥ block1.conv0.0.0                     75           75           100.0     %\n",
            "‚ö†Ô∏è üî¥ block1.conv0.1.0                     150          150          100.0     %\n",
            "  block1.convblock.0.0                   150          0            0.0       %\n",
            "  block1.convblock.1.0                   150          0            0.0       %\n",
            "  block1.convblock.2.0                   150          0            0.0       %\n",
            "  block1.convblock.3.0                   150          0            0.0       %\n",
            "  block1.convblock.4.0                   150          0            0.0       %\n",
            "  block1.convblock.5.0                   150          0            0.0       %\n",
            "  block1.convblock.6.0                   150          0            0.0       %\n",
            "  block1.convblock.7.0                   150          0            0.0       %\n",
            "‚ö†Ô∏è üî¥ block2.conv0.0.0                     45           45           100.0     %\n",
            "‚ö†Ô∏è üî¥ block2.conv0.1.0                     90           90           100.0     %\n",
            "  block2.convblock.0.0                   90           38           42.2      %\n",
            "  block2.convblock.1.0                   90           15           16.7      %\n",
            "  block2.convblock.2.0                   90           25           27.8      %\n",
            "  block2.convblock.3.0                   90           29           32.2      %\n",
            "  block2.convblock.4.0                   90           37           41.1      %\n",
            "  block2.convblock.5.0                   90           41           45.6      %\n",
            "  block2.convblock.6.0                   90           41           45.6      %\n",
            "‚ö†Ô∏è block2.convblock.7.0                   90           56           62.2      %\n",
            "‚ö†Ô∏è üî¥ block_tea.conv0.0.0                  45           45           100.0     %\n",
            "‚ö†Ô∏è üî¥ block_tea.conv0.1.0                  90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.0.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.1.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.2.0                90           85           94.4      %\n",
            "‚ö†Ô∏è block_tea.convblock.3.0                90           78           86.7      %\n",
            "‚ö†Ô∏è block_tea.convblock.4.0                90           81           90.0      %\n",
            "‚ö†Ô∏è block_tea.convblock.5.0                90           87           96.7      %\n",
            "‚ö†Ô∏è block_tea.convblock.6.0                90           82           91.1      %\n",
            "‚ö†Ô∏è block_tea.convblock.7.0                90           84           93.3      %\n",
            "‚ö†Ô∏è contextnet.conv1.conv1.0               16           16           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv1.conv2.0               16           16           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv2.conv1.0               32           32           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv2.conv2.0               32           32           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv3.conv1.0               64           64           100.0     %\n",
            "  contextnet.conv3.conv2.0               64           18           28.1      %\n",
            "  contextnet.conv4.conv1.0               128          16           12.5      %\n",
            "  contextnet.conv4.conv2.0               128          0            0.0       %\n",
            "‚ö†Ô∏è üî¥ unet.down0.conv1.0                   32           32           100.0     %\n",
            "‚ö†Ô∏è üî¥ unet.down0.conv2.0                   32           32           100.0     %\n",
            "‚ö†Ô∏è unet.down1.conv1.0                     64           63           98.4      %\n",
            "‚ö†Ô∏è unet.down1.conv2.0                     64           64           100.0     %\n",
            "  unet.down2.conv1.0                     128          0            0.0       %\n",
            "  unet.down2.conv2.0                     128          0            0.0       %\n",
            "  unet.down3.conv1.0                     256          0            0.0       %\n",
            "  unet.down3.conv2.0                     256          0            0.0       %\n",
            "‚ö†Ô∏è unet.conv                              3            3            100.0     %\n",
            "\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Sparsity: 50.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Threshold: 73.87\n",
            "\n",
            "Layer-wise pruning:\n",
            "Layer                                    Channels     Pruned       Prune %   \n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "‚ö†Ô∏è üî¥ block0.conv0.0.0                     120          120          100.0     %\n",
            "‚ö†Ô∏è üî¥ block0.conv0.1.0                     240          240          100.0     %\n",
            "  üî¥ block0.convblock.0.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.1.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.2.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.3.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.4.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.5.0                 240          0            0.0       %\n",
            "  üî¥ block0.convblock.6.0                 240          1            0.4       %\n",
            "  üî¥ block0.convblock.7.0                 240          5            2.1       %\n",
            "‚ö†Ô∏è üî¥ block1.conv0.0.0                     75           75           100.0     %\n",
            "‚ö†Ô∏è üî¥ block1.conv0.1.0                     150          150          100.0     %\n",
            "‚ö†Ô∏è block1.convblock.0.0                   150          109          72.7      %\n",
            "  block1.convblock.1.0                   150          20           13.3      %\n",
            "  block1.convblock.2.0                   150          7            4.7       %\n",
            "  block1.convblock.3.0                   150          19           12.7      %\n",
            "  block1.convblock.4.0                   150          23           15.3      %\n",
            "  block1.convblock.5.0                   150          28           18.7      %\n",
            "  block1.convblock.6.0                   150          41           27.3      %\n",
            "‚ö†Ô∏è block1.convblock.7.0                   150          104          69.3      %\n",
            "‚ö†Ô∏è üî¥ block2.conv0.0.0                     45           45           100.0     %\n",
            "‚ö†Ô∏è üî¥ block2.conv0.1.0                     90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.0.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.1.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.2.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.3.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.4.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.5.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.6.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è block2.convblock.7.0                   90           90           100.0     %\n",
            "‚ö†Ô∏è üî¥ block_tea.conv0.0.0                  45           45           100.0     %\n",
            "‚ö†Ô∏è üî¥ block_tea.conv0.1.0                  90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.0.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.1.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.2.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.3.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.4.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.5.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.6.0                90           90           100.0     %\n",
            "‚ö†Ô∏è block_tea.convblock.7.0                90           90           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv1.conv1.0               16           16           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv1.conv2.0               16           16           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv2.conv1.0               32           32           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv2.conv2.0               32           32           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv3.conv1.0               64           64           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv3.conv2.0               64           64           100.0     %\n",
            "‚ö†Ô∏è contextnet.conv4.conv1.0               128          128          100.0     %\n",
            "  contextnet.conv4.conv2.0               128          3            2.3       %\n",
            "‚ö†Ô∏è üî¥ unet.down0.conv1.0                   32           32           100.0     %\n",
            "‚ö†Ô∏è üî¥ unet.down0.conv2.0                   32           32           100.0     %\n",
            "‚ö†Ô∏è unet.down1.conv1.0                     64           64           100.0     %\n",
            "‚ö†Ô∏è unet.down1.conv2.0                     64           64           100.0     %\n",
            "‚ö†Ô∏è unet.down2.conv1.0                     128          112          87.5      %\n",
            "‚ö†Ô∏è unet.down2.conv2.0                     128          115          89.8      %\n",
            "  unet.down3.conv1.0                     256          0            0.0       %\n",
            "  unet.down3.conv2.0                     256          0            0.0       %\n",
            "‚ö†Ô∏è unet.conv                              3            3            100.0     %\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINAL SOLUTION: PROTECTED LAYER-WISE PRUNING (FIXED)\n",
        "# ============================================================\n",
        "\n",
        "def protected_layerwise_pruning(importance_dict, sparsity=0.3,\n",
        "                                min_channels_to_keep=8,\n",
        "                                protected_keywords=['conv0.0.0', 'down0', 'unet.conv']):\n",
        "    \"\"\"\n",
        "    Layer-wise pruning with protection for critical small layers.\n",
        "\n",
        "    Args:\n",
        "        importance_dict: Channel importance per layer\n",
        "        sparsity: Target sparsity for each layer (but respects min_channels_to_keep)\n",
        "        min_channels_to_keep: Minimum channels to keep per layer\n",
        "        protected_keywords: Layers to protect completely (0% pruning)\n",
        "\n",
        "    Returns:\n",
        "        prune_masks: Boolean masks per layer\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"PROTECTED LAYER-WISE PRUNING\")\n",
        "    print(f\"  Target sparsity per layer: {sparsity:.1%}\")\n",
        "    print(f\"  Min channels to keep: {min_channels_to_keep}\")\n",
        "    print(f\"  Protected keywords: {protected_keywords}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    prune_masks = {}\n",
        "    total_channels = 0\n",
        "    total_pruned = 0\n",
        "\n",
        "    protected_count = 0\n",
        "    modified_count = 0\n",
        "\n",
        "    for name, importance in importance_dict.items():\n",
        "        num_channels = len(importance)\n",
        "        total_channels += num_channels\n",
        "\n",
        "        # Check if layer is protected\n",
        "        is_protected = any(keyword in name for keyword in protected_keywords)\n",
        "\n",
        "        if is_protected:\n",
        "            # Keep ALL channels in protected layers\n",
        "            mask = torch.ones_like(importance, dtype=torch.bool)\n",
        "            prune_masks[name] = mask\n",
        "            protected_count += 1\n",
        "            print(f\"  üõ°Ô∏è  PROTECTED: {name} ({num_channels} channels)\")\n",
        "\n",
        "        else:\n",
        "            # Apply layer-wise pruning with minimum guarantee\n",
        "            num_to_keep = max(min_channels_to_keep, int(num_channels * (1 - sparsity)))\n",
        "            num_to_keep = min(num_to_keep, num_channels)  # Can't keep more than exist\n",
        "\n",
        "            if num_to_keep >= num_channels:\n",
        "                # Keep all if we're at minimum\n",
        "                mask = torch.ones_like(importance, dtype=torch.bool)\n",
        "            else:\n",
        "                # Get threshold for this layer\n",
        "                threshold = torch.sort(importance, descending=True)[0][num_to_keep - 1]\n",
        "                mask = (importance >= threshold)\n",
        "\n",
        "            prune_masks[name] = mask\n",
        "            pruned = (~mask).sum().item()\n",
        "            total_pruned += pruned\n",
        "\n",
        "            if pruned > 0:\n",
        "                modified_count += 1\n",
        "                prune_pct = (pruned / num_channels) * 100\n",
        "                if prune_pct > 50:\n",
        "                    print(f\"  ‚ö†Ô∏è  {name}: {num_channels-pruned}/{num_channels} kept ({prune_pct:.1f}% pruned)\")\n",
        "\n",
        "    actual_sparsity = total_pruned / total_channels\n",
        "    print(\"\\n\" + \"‚îÄ\"*60)\n",
        "    print(\"Summary:\")\n",
        "    print(f\"  Protected layers: {protected_count}\")\n",
        "    print(f\"  Modified layers: {modified_count}\")\n",
        "    print(f\"  Total: {total_pruned}/{total_channels} channels pruned\")\n",
        "    print(f\"  Actual sparsity: {actual_sparsity:.1%}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return prune_masks\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# TEST PROTECTED LAYER-WISE PRUNING\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING PROTECTED LAYER-WISE PRUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define which layers to protect (all first conv layers + small critical layers)\n",
        "protected_layers = [\n",
        "    'conv0.0.0',      # All first convs in blocks\n",
        "    'down0',          # First downsampling layers\n",
        "    'conv1.conv',     # Very small context layers\n",
        "    'unet.conv',      # Final 3-channel conv\n",
        "]\n",
        "\n",
        "# Test different sparsity levels\n",
        "sparsity_levels_protected = [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "results_protected = {}\n",
        "\n",
        "for sparsity in sparsity_levels_protected:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Testing Protected Layer-wise Sparsity: {sparsity:.1%}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Create protected layer-wise masks\n",
        "    masks_protected = protected_layerwise_pruning(\n",
        "        importance_dict_v2,\n",
        "        sparsity=sparsity,\n",
        "        min_channels_to_keep=8,  # Never go below 8 channels\n",
        "        protected_keywords=protected_layers\n",
        "    )\n",
        "\n",
        "    # Apply pruning\n",
        "    model_protected = apply_soft_pruning_v2(model, masks_protected)\n",
        "    model_protected.device()\n",
        "\n",
        "    # Evaluate\n",
        "    print(f\"\\nEvaluating on 50 samples...\")\n",
        "    results = quick_evaluate_v2(model_protected, UCF_PATH, num_samples=50)\n",
        "    results_protected[sparsity] = results\n",
        "\n",
        "    psnr_drop = 35.292 - results['PSNR']\n",
        "    ssim_drop = 0.9690 - results['SSIM']\n",
        "\n",
        "    print(f\"\\nüìä Results:\")\n",
        "    print(f\"   PSNR: {results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"   SSIM: {results['SSIM']:.4f} (drop: {ssim_drop:.4f})\")\n",
        "    print(f\"   Inference: {results['Inference_Time_ms']:.2f} ms ({results['FPS']:.1f} FPS)\")\n",
        "\n",
        "    # Quality assessment\n",
        "    if psnr_drop <= 0.5:\n",
        "        status = \"‚úÖ EXCELLENT\"\n",
        "    elif psnr_drop <= 1.0:\n",
        "        status = \"‚úÖ GOOD\"\n",
        "    elif psnr_drop <= 2.0:\n",
        "        status = \"‚ö†Ô∏è  ACCEPTABLE\"\n",
        "    else:\n",
        "        status = \"‚ùå POOR\"\n",
        "\n",
        "    print(f\"   Quality: {status}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model_protected\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# FINAL COMPARISON\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON: Global vs Protected Layer-wise\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n{'Sparsity':<12} {'Global':<15} {'Protected':<15} {'Improvement':<15}\")\n",
        "print(\"‚îÄ\"*60)\n",
        "\n",
        "for sparsity in [0.2, 0.3, 0.4, 0.5]:\n",
        "    if sparsity in pruning_results_v2:\n",
        "        global_psnr = pruning_results_v2[sparsity]['PSNR']\n",
        "    else:\n",
        "        global_psnr = 0\n",
        "\n",
        "    if sparsity in results_protected:\n",
        "        protected_psnr = results_protected[sparsity]['PSNR']\n",
        "    else:\n",
        "        protected_psnr = 0\n",
        "\n",
        "    if global_psnr > 0 and protected_psnr > 0:\n",
        "        improvement = protected_psnr - global_psnr\n",
        "        indicator = \"‚úÖ MAJOR\" if improvement > 10 else (\"‚úÖ\" if improvement > 5 else \"‚ö†Ô∏è \")\n",
        "        print(f\"{sparsity:<12.1%} {global_psnr:<15.3f} {protected_psnr:<15.3f} {indicator} {improvement:+.2f} dB\")\n",
        "\n",
        "# ============================================================\n",
        "# SELECT BEST AND EVALUATE ON FULL DATASET\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SELECTING BEST CONFIGURATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Find best sparsity with acceptable quality\n",
        "acceptable_protected = {s: r for s, r in results_protected.items()\n",
        "                       if (35.292 - r['PSNR']) <= 1.5}\n",
        "\n",
        "if len(acceptable_protected) > 0:\n",
        "    best_sparsity_protected = max(acceptable_protected.keys())\n",
        "    best_results = acceptable_protected[best_sparsity_protected]\n",
        "\n",
        "    print(f\"\\n‚úÖ SELECTED: {best_sparsity_protected:.1%} sparsity\")\n",
        "    print(f\"   PSNR: {best_results['PSNR']:.3f} dB\")\n",
        "    print(f\"   Drop: {35.292 - best_results['PSNR']:.3f} dB\")\n",
        "\n",
        "    # Full evaluation\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FULL EVALUATION ON UCF-101\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Creating final model with {best_sparsity_protected:.1%} sparsity...\")\n",
        "\n",
        "    final_masks = protected_layerwise_pruning(\n",
        "        importance_dict_v2,\n",
        "        sparsity=best_sparsity_protected,\n",
        "        min_channels_to_keep=8,\n",
        "        protected_keywords=protected_layers\n",
        "    )\n",
        "\n",
        "    final_model = apply_soft_pruning_v2(model, final_masks)\n",
        "    final_model.device()\n",
        "\n",
        "    # Calculate FLOPs for the final model\n",
        "    from thop import profile, clever_format\n",
        "    try:\n",
        "        sample_img0 = torch.randn(1, 3, 256, 256).to(next(final_model.parameters()).device)\n",
        "        sample_img1 = torch.randn(1, 3, 256, 256).to(next(final_model.parameters()).device)\n",
        "        with torch.no_grad():\n",
        "            flops, params = profile(final_model.flownet, inputs=(torch.cat([sample_img0, sample_img1], 1),), verbose=False)\n",
        "        flops_str, params_str = clever_format([flops, params], \"%.3f\")\n",
        "        print(f\"\\nFLOPs (256x256 input): {flops_str}\")\n",
        "        print(f\"Parameters (from profiler): {params_str}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nFLOPs calculation failed: {e}\")\n",
        "        flops_str = \"N/A\"\n",
        "\n",
        "\n",
        "    print(f\"\\nEvaluating on 379 sequences...\")\n",
        "    print(\"‚è±Ô∏è  This will take 5-10 minutes...\")\n",
        "\n",
        "    final_results_full = quick_evaluate_v2(final_model, UCF_PATH, num_samples=379)\n",
        "\n",
        "    # Final report\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL RESULTS - PROTECTED LAYER-WISE PRUNING\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\nüìä BASELINE:\")\n",
        "    print(f\"   PSNR: 35.292 dB\")\n",
        "    print(f\"   SSIM: 0.9690\")\n",
        "    # Assuming baseline FLOPs is needed for comparison - get from the first cell output\n",
        "    baseline_flops_str = \"11.684G\"\n",
        "    print(f\"   FLOPs (256x256): {baseline_flops_str}\")\n",
        "\n",
        "\n",
        "    print(f\"\\nüìä OPTIMIZED ({best_sparsity_protected:.1%} sparsity):\")\n",
        "    psnr_drop_final = 35.292 - final_results_full['PSNR']\n",
        "    print(f\"   PSNR: {final_results_full['PSNR']:.3f} dB (Œî: {psnr_drop_final:.3f} dB)\")\n",
        "    print(f\"   SSIM: {final_results_full['SSIM']:.4f}\")\n",
        "    print(f\"   Inference: {final_results_full['Inference_Time_ms']:.2f} ms\")\n",
        "    print(f\"   FPS: {final_results_full['FPS']:.1f}\")\n",
        "    print(f\"   FLOPs (256x256): {flops_str}\")\n",
        "\n",
        "\n",
        "    if psnr_drop_final <= 1.0:\n",
        "        print(f\"\\n‚úÖ SUCCESS! Quality degradation is acceptable\")\n",
        "        print(f\"   Proceed to quantization or video processing\")\n",
        "    elif psnr_drop_final <= 2.0:\n",
        "        print(f\"\\n‚ö†Ô∏è  ACCEPTABLE. Fine-tuning recommended\")\n",
        "    else:\n",
        "        print(f\"\\n‚ùå Quality drop too high. Needs fine-tuning\")\n",
        "\n",
        "    # Save\n",
        "    torch.save({\n",
        "        'flownet_state_dict': final_model.flownet.state_dict(),\n",
        "        'sparsity': best_sparsity_protected,\n",
        "        'masks': {k: v.numpy() for k, v in final_masks.items()},\n",
        "        'results': final_results_full,\n",
        "        'method': 'protected_layerwise',\n",
        "        'flops': flops_str\n",
        "    }, '/content/pruned_model_FINAL.pth')\n",
        "\n",
        "    print(f\"\\nüíæ Model saved to '/content/pruned_model_FINAL.pth'\")\n",
        "\n",
        "else:\n",
        "    print(\"\\n‚ùå No acceptable configuration found\")\n",
        "    print(\"   All sparsity levels degrade quality too much\")\n",
        "    print(\"   Recommendation: Use lower sparsity or different pruning strategy\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ PROTECTED LAYER-WISE PRUNING COMPLETE!\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDhjiRHwkcui",
        "outputId": "0e553464-0dae-4088-f79c-c07436430691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TESTING PROTECTED LAYER-WISE PRUNING\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Testing Protected Layer-wise Sparsity: 20.0%\n",
            "============================================================\n",
            "============================================================\n",
            "PROTECTED LAYER-WISE PRUNING\n",
            "  Target sparsity per layer: 20.0%\n",
            "  Min channels to keep: 8\n",
            "  Protected keywords: ['conv0.0.0', 'down0', 'conv1.conv', 'unet.conv']\n",
            "============================================================\n",
            "  üõ°Ô∏è  PROTECTED: block0.conv0.0.0 (120 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block1.conv0.0.0 (75 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block2.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block_tea.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv1.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv2.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv1.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv2.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.conv (3 channels)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Summary:\n",
            "  Protected layers: 9\n",
            "  Modified layers: 48\n",
            "  Total: 1300/6858 channels pruned\n",
            "  Actual sparsity: 19.0%\n",
            "============================================================\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 1300/6858 channels (19.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 31.839 dB (drop: 3.453 dB)\n",
            "   SSIM: 0.9612 (drop: 0.0078)\n",
            "   Inference: 10.12 ms (98.8 FPS)\n",
            "   Quality: ‚ùå POOR\n",
            "\n",
            "============================================================\n",
            "Testing Protected Layer-wise Sparsity: 30.0%\n",
            "============================================================\n",
            "============================================================\n",
            "PROTECTED LAYER-WISE PRUNING\n",
            "  Target sparsity per layer: 30.0%\n",
            "  Min channels to keep: 8\n",
            "  Protected keywords: ['conv0.0.0', 'down0', 'conv1.conv', 'unet.conv']\n",
            "============================================================\n",
            "  üõ°Ô∏è  PROTECTED: block0.conv0.0.0 (120 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block1.conv0.0.0 (75 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block2.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block_tea.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv1.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv2.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv1.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv2.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.conv (3 channels)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Summary:\n",
            "  Protected layers: 9\n",
            "  Modified layers: 48\n",
            "  Total: 1967/6858 channels pruned\n",
            "  Actual sparsity: 28.7%\n",
            "============================================================\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 1967/6858 channels (28.7%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 31.910 dB (drop: 3.382 dB)\n",
            "   SSIM: 0.9634 (drop: 0.0056)\n",
            "   Inference: 12.36 ms (80.9 FPS)\n",
            "   Quality: ‚ùå POOR\n",
            "\n",
            "============================================================\n",
            "Testing Protected Layer-wise Sparsity: 40.0%\n",
            "============================================================\n",
            "============================================================\n",
            "PROTECTED LAYER-WISE PRUNING\n",
            "  Target sparsity per layer: 40.0%\n",
            "  Min channels to keep: 8\n",
            "  Protected keywords: ['conv0.0.0', 'down0', 'conv1.conv', 'unet.conv']\n",
            "============================================================\n",
            "  üõ°Ô∏è  PROTECTED: block0.conv0.0.0 (120 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block1.conv0.0.0 (75 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block2.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block_tea.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv1.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv2.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv1.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv2.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.conv (3 channels)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Summary:\n",
            "  Protected layers: 9\n",
            "  Modified layers: 48\n",
            "  Total: 2596/6858 channels pruned\n",
            "  Actual sparsity: 37.9%\n",
            "============================================================\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 2596/6858 channels (37.9%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 32.173 dB (drop: 3.119 dB)\n",
            "   SSIM: 0.9633 (drop: 0.0057)\n",
            "   Inference: 9.97 ms (100.3 FPS)\n",
            "   Quality: ‚ùå POOR\n",
            "\n",
            "============================================================\n",
            "Testing Protected Layer-wise Sparsity: 50.0%\n",
            "============================================================\n",
            "============================================================\n",
            "PROTECTED LAYER-WISE PRUNING\n",
            "  Target sparsity per layer: 50.0%\n",
            "  Min channels to keep: 8\n",
            "  Protected keywords: ['conv0.0.0', 'down0', 'conv1.conv', 'unet.conv']\n",
            "============================================================\n",
            "  üõ°Ô∏è  PROTECTED: block0.conv0.0.0 (120 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block1.conv0.0.0 (75 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block2.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: block_tea.conv0.0.0 (45 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv1.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv2.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv1.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv2.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.conv (3 channels)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Summary:\n",
            "  Protected layers: 9\n",
            "  Modified layers: 48\n",
            "  Total: 3237/6858 channels pruned\n",
            "  Actual sparsity: 47.2%\n",
            "============================================================\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 3237/6858 channels (47.2%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 32.413 dB (drop: 2.879 dB)\n",
            "   SSIM: 0.9646 (drop: 0.0044)\n",
            "   Inference: 10.09 ms (99.1 FPS)\n",
            "   Quality: ‚ùå POOR\n",
            "\n",
            "============================================================\n",
            "Testing Protected Layer-wise Sparsity: 60.0%\n",
            "============================================================\n",
            "============================================================\n",
            "PROTECTED LAYER-WISE PRUNING\n",
            "  Target sparsity per layer: 60.0%\n",
            "  Min channels to keep: 8\n",
            "  Protected keywords: ['conv0.0.0', 'down0', 'conv1.conv', 'unet.conv']\n",
            "============================================================\n",
            "  üõ°Ô∏è  PROTECTED: block0.conv0.0.0 (120 channels)\n",
            "  ‚ö†Ô∏è  block0.conv0.1.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.0.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.1.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.2.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.3.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.4.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.5.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.6.0: 96/240 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block0.convblock.7.0: 96/240 kept (60.0% pruned)\n",
            "  üõ°Ô∏è  PROTECTED: block1.conv0.0.0 (75 channels)\n",
            "  ‚ö†Ô∏è  block1.conv0.1.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.0.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.1.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.2.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.3.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.4.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.5.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.6.0: 60/150 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block1.convblock.7.0: 60/150 kept (60.0% pruned)\n",
            "  üõ°Ô∏è  PROTECTED: block2.conv0.0.0 (45 channels)\n",
            "  ‚ö†Ô∏è  block2.conv0.1.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.0.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.1.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.2.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.3.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.4.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.5.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.6.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block2.convblock.7.0: 36/90 kept (60.0% pruned)\n",
            "  üõ°Ô∏è  PROTECTED: block_tea.conv0.0.0 (45 channels)\n",
            "  ‚ö†Ô∏è  block_tea.conv0.1.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.0.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.1.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.2.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.3.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.4.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.5.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.6.0: 36/90 kept (60.0% pruned)\n",
            "  ‚ö†Ô∏è  block_tea.convblock.7.0: 36/90 kept (60.0% pruned)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv1.0 (16 channels)\n",
            "  üõ°Ô∏è  PROTECTED: contextnet.conv1.conv2.0 (16 channels)\n",
            "  ‚ö†Ô∏è  contextnet.conv2.conv1.0: 12/32 kept (62.5% pruned)\n",
            "  ‚ö†Ô∏è  contextnet.conv2.conv2.0: 12/32 kept (62.5% pruned)\n",
            "  ‚ö†Ô∏è  contextnet.conv3.conv1.0: 25/64 kept (60.9% pruned)\n",
            "  ‚ö†Ô∏è  contextnet.conv3.conv2.0: 25/64 kept (60.9% pruned)\n",
            "  ‚ö†Ô∏è  contextnet.conv4.conv1.0: 51/128 kept (60.2% pruned)\n",
            "  ‚ö†Ô∏è  contextnet.conv4.conv2.0: 51/128 kept (60.2% pruned)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv1.0 (32 channels)\n",
            "  üõ°Ô∏è  PROTECTED: unet.down0.conv2.0 (32 channels)\n",
            "  ‚ö†Ô∏è  unet.down1.conv1.0: 25/64 kept (60.9% pruned)\n",
            "  ‚ö†Ô∏è  unet.down1.conv2.0: 25/64 kept (60.9% pruned)\n",
            "  ‚ö†Ô∏è  unet.down2.conv1.0: 51/128 kept (60.2% pruned)\n",
            "  ‚ö†Ô∏è  unet.down2.conv2.0: 51/128 kept (60.2% pruned)\n",
            "  ‚ö†Ô∏è  unet.down3.conv1.0: 102/256 kept (60.2% pruned)\n",
            "  ‚ö†Ô∏è  unet.down3.conv2.0: 102/256 kept (60.2% pruned)\n",
            "  üõ°Ô∏è  PROTECTED: unet.conv (3 channels)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Summary:\n",
            "  Protected layers: 9\n",
            "  Modified layers: 48\n",
            "  Total: 3890/6858 channels pruned\n",
            "  Actual sparsity: 56.7%\n",
            "============================================================\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 3890/6858 channels (56.7%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                           "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 32.700 dB (drop: 2.592 dB)\n",
            "   SSIM: 0.9646 (drop: 0.0044)\n",
            "   Inference: 10.45 ms (95.7 FPS)\n",
            "   Quality: ‚ùå POOR\n",
            "\n",
            "============================================================\n",
            "COMPARISON: Global vs Protected Layer-wise\n",
            "============================================================\n",
            "\n",
            "Sparsity     Global          Protected       Improvement    \n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "20.0%        19.840          31.839          ‚úÖ MAJOR +12.00 dB\n",
            "30.0%        25.319          31.910          ‚úÖ +6.59 dB\n",
            "40.0%        31.874          32.173          ‚ö†Ô∏è  +0.30 dB\n",
            "50.0%        32.361          32.413          ‚ö†Ô∏è  +0.05 dB\n",
            "\n",
            "============================================================\n",
            "SELECTING BEST CONFIGURATION\n",
            "============================================================\n",
            "\n",
            "‚ùå No acceptable configuration found\n",
            "   All sparsity levels degrade quality too much\n",
            "   Recommendation: Use lower sparsity or different pruning strategy\n",
            "\n",
            "============================================================\n",
            "‚úÖ PROTECTED LAYER-WISE PRUNING COMPLETE!\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ATTEMPT 1"
      ],
      "metadata": {
        "id": "Pu3p3crFzalD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# COMPLETE CORRECTED PRUNING IMPLEMENTATION + TABLE EXPORT\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import pandas as pd\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ============================================================\n",
        "# CORRECTED HELPER FUNCTIONS (as provided)\n",
        "# ============================================================\n",
        "\n",
        "def compute_channel_importance_v2(module, layer_types=[nn.Conv2d]):\n",
        "    \"\"\"\n",
        "    Compute L1-norm importance for each channel (VERIFIED CORRECT)\n",
        "    \"\"\"\n",
        "    importance_dict = {}\n",
        "\n",
        "    for name, layer in module.named_modules():\n",
        "        if isinstance(layer, tuple(layer_types)):\n",
        "            weight = layer.weight.data\n",
        "            # L1 norm per output channel: sum over [in_channels, H, W]\n",
        "            importance = torch.norm(weight.view(weight.size(0), -1), p=1, dim=1)\n",
        "            importance_dict[name] = importance.cpu()\n",
        "\n",
        "    print(f\"‚úÖ Analyzed {len(importance_dict)} convolutional layers\")\n",
        "\n",
        "    # Debug statistics\n",
        "    all_imp = torch.cat([imp for imp in importance_dict.values()])\n",
        "    print(f\"   Importance range: [{all_imp.min():.2f}, {all_imp.max():.2f}], Mean: {all_imp.mean():.2f}\")\n",
        "\n",
        "    return importance_dict\n",
        "\n",
        "\n",
        "def global_channel_pruning_v2(importance_dict, sparsity=0.5):\n",
        "    \"\"\"\n",
        "    CORRECTED: Prune channels with SMALLEST importance (least important)\n",
        "\n",
        "    Args:\n",
        "        importance_dict: Channel importance scores\n",
        "        sparsity: Fraction of channels to REMOVE (0-1)\n",
        "\n",
        "    Returns:\n",
        "        prune_masks: Boolean masks (True = KEEP, False = PRUNE)\n",
        "    \"\"\"\n",
        "    # Flatten all importance scores\n",
        "    all_importance = torch.cat([imp for imp in importance_dict.values()])\n",
        "    total_channels = len(all_importance)\n",
        "\n",
        "    # Calculate how many to KEEP\n",
        "    num_to_keep = int(total_channels * (1 - sparsity))\n",
        "\n",
        "    # Sort importance in DESCENDING order and get threshold\n",
        "    # Channels with importance >= threshold will be KEPT\n",
        "    sorted_importance = torch.sort(all_importance, descending=True)[0]\n",
        "    threshold = sorted_importance[num_to_keep - 1] if num_to_keep > 0 else sorted_importance[-1]\n",
        "\n",
        "    print(f\"   Sparsity: {sparsity:.1%}\")\n",
        "    print(f\"   Total channels: {total_channels}\")\n",
        "    print(f\"   Channels to keep: {num_to_keep}\")\n",
        "    print(f\"   Threshold: {threshold:.6f}\")\n",
        "    print(f\"   Logic: KEEP channels with importance >= {threshold:.6f}\")\n",
        "\n",
        "    # Create masks: True = KEEP, False = PRUNE\n",
        "    prune_masks = {}\n",
        "    total_kept = 0\n",
        "\n",
        "    for name, importance in importance_dict.items():\n",
        "        # CORRECTED: Keep channels with importance >= threshold\n",
        "        mask = (importance >= threshold)\n",
        "        prune_masks[name] = mask\n",
        "        total_kept += mask.sum().item()\n",
        "\n",
        "    actual_sparsity = 1 - (total_kept / total_channels)\n",
        "    actual_kept_pct = (total_kept / total_channels) * 100\n",
        "\n",
        "    print(f\"   Result: {total_kept}/{total_channels} channels kept ({actual_kept_pct:.1f}%)\")\n",
        "    print(f\"   Actual sparsity: {actual_sparsity:.1%}\")\n",
        "\n",
        "    return prune_masks\n",
        "\n",
        "\n",
        "def apply_soft_pruning_v2(model, prune_masks):\n",
        "    \"\"\"\n",
        "    Apply soft pruning by zeroing out weights (VERIFIED CORRECT)\n",
        "\n",
        "    NOTE: This function creates a fresh RIFEModel instance and loads weights from 'train_log'.\n",
        "    If you want to apply masks directly to an in-memory model, adjust accordingly.\n",
        "    \"\"\"\n",
        "    # Import inside function to avoid errors if path differs\n",
        "    try:\n",
        "        from model.RIFE import Model as RIFEModel\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Could not import RIFEModel from model.RIFE. Make sure your project path is correct.\") from e\n",
        "\n",
        "    # Create fresh model instance\n",
        "    pruned_model = RIFEModel()\n",
        "    pruned_model.load_model('train_log')\n",
        "    pruned_model.eval()\n",
        "\n",
        "    # Apply masks\n",
        "    total_channels = 0\n",
        "    zeroed_channels = 0\n",
        "    layers_modified = 0\n",
        "\n",
        "    for name, module in pruned_model.flownet.named_modules():\n",
        "        if name in prune_masks:\n",
        "            mask = prune_masks[name]\n",
        "            # Some modules may be on CPU - move mask accordingly\n",
        "            if any(p is None for p in module.parameters()):\n",
        "                device = torch.device('cpu')\n",
        "            else:\n",
        "                device = next(module.parameters()).device\n",
        "\n",
        "            # Create weight mask: expand to [out_ch, in_ch, H, W]\n",
        "            weight_mask = mask.view(-1, 1, 1, 1).expand_as(module.weight).to(device)\n",
        "\n",
        "            # Apply mask: multiply weights by mask (zeros out pruned channels)\n",
        "            module.weight.data *= weight_mask\n",
        "\n",
        "            # Apply to bias if exists\n",
        "            if module.bias is not None:\n",
        "                bias_mask = mask.to(device)\n",
        "                module.bias.data *= bias_mask\n",
        "\n",
        "            # Track statistics\n",
        "            zeroed = (~mask).sum().item()\n",
        "            total = len(mask)\n",
        "            zeroed_channels += zeroed\n",
        "            total_channels += total\n",
        "            layers_modified += 1\n",
        "\n",
        "    if total_channels == 0:\n",
        "        print(\"‚ö†Ô∏è  Warning: No layers matched the provided masks.\")\n",
        "    else:\n",
        "        print(f\"   Applied masks to {layers_modified} layers\")\n",
        "        print(f\"   Zeroed {zeroed_channels}/{total_channels} channels ({zeroed_channels/total_channels*100:.1f}%)\")\n",
        "\n",
        "    return pruned_model\n",
        "\n",
        "\n",
        "def quick_evaluate_v2(model, dataset_path, num_samples=50):\n",
        "    \"\"\"\n",
        "    Quick evaluation (same as before, just renamed for consistency)\n",
        "    \"\"\"\n",
        "    import cv2\n",
        "    from model.pytorch_msssim import ssim_matlab\n",
        "\n",
        "    model.eval()\n",
        "    # if model has flownet use its parameters for device detection, else CPU\n",
        "    try:\n",
        "        device = next(model.flownet.parameters()).device\n",
        "    except Exception:\n",
        "        device = torch.device('cpu')\n",
        "\n",
        "    dirs = sorted(os.listdir(dataset_path))[:num_samples]\n",
        "    psnr_list, ssim_list, time_list = [], [], []\n",
        "\n",
        "    for d in tqdm(dirs, desc=\"Evaluating\", leave=False):\n",
        "        img0_path = os.path.join(dataset_path, d, 'frame_00.png')\n",
        "        img1_path = os.path.join(dataset_path, d, 'frame_02.png')\n",
        "        gt_path = os.path.join(dataset_path, d, 'frame_01_gt.png')\n",
        "\n",
        "        if not all(map(os.path.exists, [img0_path, img1_path, gt_path])):\n",
        "            continue\n",
        "\n",
        "        img0 = torch.tensor(cv2.imread(img0_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "        img1 = torch.tensor(cv2.imread(img1_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "        gt = torch.tensor(cv2.imread(gt_path).transpose(2,0,1)/255.).float().unsqueeze(0).to(device)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        start_time = time.time()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = model.inference(img0, img1)[0]\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.synchronize()\n",
        "        time_list.append((time.time() - start_time) * 1000)\n",
        "\n",
        "        ssim_val = ssim_matlab(gt, torch.round(pred*255).unsqueeze(0)/255).detach().cpu().numpy()\n",
        "        ssim_list.append(float(ssim_val))\n",
        "\n",
        "        out = pred.detach().cpu().numpy().transpose(1,2,0)\n",
        "        out = np.round(out*255)/255.\n",
        "        gt_np = gt[0].cpu().numpy().transpose(1,2,0)\n",
        "        mse = ((gt_np - out)**2).mean()\n",
        "        psnr = -10 * math.log10(mse + 1e-8)\n",
        "        psnr_list.append(psnr)\n",
        "\n",
        "    return {\n",
        "        'PSNR': np.mean(psnr_list) if len(psnr_list) > 0 else float('nan'),\n",
        "        'SSIM': np.mean(ssim_list) if len(ssim_list) > 0 else float('nan'),\n",
        "        'Inference_Time_ms': np.mean(time_list) if len(time_list) > 0 else float('nan'),\n",
        "        'FPS': 1000. / np.mean(time_list) if len(time_list) > 0 else float('nan')\n",
        "    }\n",
        "\n",
        "# Simple parameter counting helper (if not already defined)\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# ============================================================\n",
        "# STEP 1: DIAGNOSTIC - COMPARE OLD VS NEW PRUNING\n",
        "# ============================================================\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: DIAGNOSTIC - COMPARE OLD VS NEW PRUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if 'model' not in globals():\n",
        "    raise RuntimeError(\"Model not found. Run baseline cell first or ensure `model` exists in the global namespace.\")\n",
        "\n",
        "UCF_PATH = \"/content/drive/MyDrive/UCF-101/ucf101_interp_ours\"\n",
        "baseline_psnr = 35.292\n",
        "baseline_ssim = 0.9690\n",
        "\n",
        "# Compute importance with new function\n",
        "print(\"\\nComputing channel importance...\")\n",
        "importance_dict_v2 = compute_channel_importance_v2(model.flownet)\n",
        "\n",
        "# Test both methods on same sparsity\n",
        "sparsity_test = 0.3\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"COMPARING METHODS AT {sparsity_test:.0%} SPARSITY\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Try old method if available (wrap in try/except)\n",
        "results_old = {'PSNR': float('nan'), 'SSIM': float('nan')}\n",
        "try:\n",
        "    if 'global_channel_pruning' in globals() and 'apply_soft_pruning' in globals():\n",
        "        print(\"\\nüî¥ OLD METHOD (inverted logic):\")\n",
        "        masks_old = global_channel_pruning(importance_dict, sparsity_test)  # old function from earlier cell\n",
        "        model_old = apply_soft_pruning(model, masks_old)\n",
        "        try:\n",
        "            model_old.device()\n",
        "        except Exception:\n",
        "            pass\n",
        "        results_old = quick_evaluate(model_old, UCF_PATH, num_samples=20)\n",
        "        print(f\"   PSNR: {results_old['PSNR']:.3f} dB\")\n",
        "        print(f\"   SSIM: {results_old['SSIM']:.4f}\")\n",
        "        del model_old\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è Old pruning functions not found; skipping old-method diagnostic.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Skipping old-method diagnostic due to error: {e}\")\n",
        "\n",
        "# New corrected method\n",
        "print(\"\\n‚úÖ NEW METHOD (corrected logic):\")\n",
        "masks_new = global_channel_pruning_v2(importance_dict_v2, sparsity_test)\n",
        "model_new = apply_soft_pruning_v2(model, masks_new)\n",
        "try:\n",
        "    model_new.device()\n",
        "except Exception:\n",
        "    pass\n",
        "results_new = quick_evaluate_v2(model_new, UCF_PATH, num_samples=20)\n",
        "print(f\"   PSNR: {results_new['PSNR']:.3f} dB\")\n",
        "print(f\"   SSIM: {results_new['SSIM']:.4f}\")\n",
        "\n",
        "# Comparison\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"DIAGNOSTIC RESULT:\")\n",
        "print(f\"{'='*60}\")\n",
        "improvement = results_new['PSNR'] - (results_old['PSNR'] if not math.isnan(results_old['PSNR']) else float('nan'))\n",
        "if not math.isnan(improvement) and improvement > 5.0:\n",
        "    print(f\"‚úÖ MAJOR IMPROVEMENT: +{improvement:.2f} dB\")\n",
        "    print(f\"   Old logic was definitely inverted!\")\n",
        "    print(f\"   Proceeding with corrected pruning...\")\n",
        "elif not math.isnan(improvement) and improvement > 1.0:\n",
        "    print(f\"‚úÖ IMPROVEMENT: +{improvement:.2f} dB\")\n",
        "    print(f\"   New logic is better\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è  MINIMAL DIFFERENCE: {improvement if not math.isnan(improvement) else 'N/A'} dB\")\n",
        "    print(f\"   Issue might be elsewhere\")\n",
        "\n",
        "# Cleanup partial objects if exist\n",
        "try:\n",
        "    del model_new\n",
        "except Exception:\n",
        "    pass\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# STEP 2: RUN CORRECTED PRUNING EXPERIMENTS\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 2: CORRECTED PRUNING EXPERIMENTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "sparsity_levels = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
        "pruning_results_v2 = {}\n",
        "\n",
        "for sparsity in sparsity_levels:\n",
        "    print(f\"\\n{'‚îÄ'*60}\")\n",
        "    print(f\"Testing sparsity: {sparsity:.1%}\")\n",
        "    print(f\"{'‚îÄ'*60}\")\n",
        "\n",
        "    # Create masks with corrected method\n",
        "    prune_masks = global_channel_pruning_v2(importance_dict_v2, sparsity)\n",
        "\n",
        "    # Apply pruning\n",
        "    pruned_model = apply_soft_pruning_v2(model, prune_masks)\n",
        "    try:\n",
        "        pruned_model.device()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Evaluate\n",
        "    print(f\"\\nEvaluating on 50 samples...\")\n",
        "    results = quick_evaluate_v2(pruned_model, UCF_PATH, num_samples=50)\n",
        "    pruning_results_v2[sparsity] = results\n",
        "\n",
        "    # Calculate metrics\n",
        "    psnr_drop = baseline_psnr - results['PSNR']\n",
        "    ssim_drop = baseline_ssim - results['SSIM']\n",
        "\n",
        "    print(f\"\\nüìä Results:\")\n",
        "    print(f\"   PSNR: {results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"   SSIM: {results['SSIM']:.4f} (drop: {ssim_drop:.4f})\")\n",
        "    print(f\"   Inference: {results['Inference_Time_ms']:.2f} ms ({results['FPS']:.1f} FPS)\")\n",
        "\n",
        "    # Clear memory\n",
        "    try:\n",
        "        del pruned_model\n",
        "    except Exception:\n",
        "        pass\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# ============================================================\n",
        "# STEP 3: SELECT OPTIMAL SPARSITY\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 3: SELECTING OPTIMAL SPARSITY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\n{'Sparsity':<10} {'PSNR':<10} {'Drop':<10} {'SSIM':<10} {'Status':<15}\")\n",
        "print(\"‚îÄ\"*60)\n",
        "\n",
        "acceptable = {}\n",
        "for sparsity in sorted(pruning_results_v2.keys()):\n",
        "    results = pruning_results_v2[sparsity]\n",
        "    psnr_drop = baseline_psnr - results['PSNR']\n",
        "\n",
        "    if psnr_drop <= 0.5:\n",
        "        status = \"‚úÖ Excellent\"\n",
        "        acceptable[sparsity] = results\n",
        "    elif psnr_drop <= 1.0:\n",
        "        status = \"‚úÖ Good\"\n",
        "        acceptable[sparsity] = results\n",
        "    elif psnr_drop <= 1.5:\n",
        "        status = \"‚ö†Ô∏è  Marginal\"\n",
        "    else:\n",
        "        status = \"‚ùå Too high\"\n",
        "\n",
        "    print(f\"{sparsity:<10.1%} {results['PSNR']:<10.3f} {psnr_drop:<10.3f} {results['SSIM']:<10.4f} {status:<15}\")\n",
        "\n",
        "print(\"\\n\" + \"‚îÄ\"*60)\n",
        "\n",
        "if len(acceptable) > 0:\n",
        "    # Choose highest acceptable sparsity (most compression)\n",
        "    best_sparsity = max(acceptable.keys())\n",
        "    best_results = acceptable[best_sparsity]\n",
        "    psnr_drop = baseline_psnr - best_results['PSNR']\n",
        "\n",
        "    print(f\"‚úÖ SELECTED: {best_sparsity:.1%} sparsity\")\n",
        "    print(f\"   PSNR: {best_results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"   SSIM: {best_results['SSIM']:.4f}\")\n",
        "    print(f\"   Quality: {'Excellent' if psnr_drop <= 0.5 else 'Good'}\")\n",
        "else:\n",
        "    # Use minimum sparsity\n",
        "    best_sparsity = min(pruning_results_v2.keys())\n",
        "    best_results = pruning_results_v2[best_sparsity]\n",
        "    psnr_drop = baseline_psnr - best_results['PSNR']\n",
        "\n",
        "    print(f\"‚ö†Ô∏è  SELECTED: {best_sparsity:.1%} sparsity (minimum)\")\n",
        "    print(f\"   PSNR: {best_results['PSNR']:.3f} dB (drop: {psnr_drop:.3f} dB)\")\n",
        "    print(f\"   Note: All sparsity levels had high degradation\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 4: FINAL EVALUATION ON FULL DATASET\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STEP 4: FULL EVALUATION ON UCF-101\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nCreating final pruned model ({best_sparsity:.1%} sparsity)...\")\n",
        "final_masks = global_channel_pruning_v2(importance_dict_v2, best_sparsity)\n",
        "final_pruned_model = apply_soft_pruning_v2(model, final_masks)\n",
        "try:\n",
        "    final_pruned_model.device()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "print(f\"\\nEvaluating on full UCF-101 dataset (379 sequences)...\")\n",
        "print(\"‚è±Ô∏è  This may take several minutes depending on your runtime and hardware...\")\n",
        "\n",
        "final_results = quick_evaluate_v2(final_pruned_model, UCF_PATH, num_samples=379)\n",
        "\n",
        "# ============================================================\n",
        "# STEP 5: FINAL REPORT\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FINAL RESULTS - CORRECTED PRUNING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nüìä BASELINE MODEL:\")\n",
        "print(f\"   PSNR: {baseline_psnr:.3f} dB\")\n",
        "print(f\"   SSIM: {baseline_ssim:.4f}\")\n",
        "print(f\"   Parameters: {count_parameters(model):,} ({count_parameters(model)/1e6:.2f}M)\")\n",
        "\n",
        "print(f\"\\nüìä PRUNED MODEL (Sparsity: {best_sparsity:.1%}):\")\n",
        "psnr_drop_final = baseline_psnr - final_results['PSNR']\n",
        "ssim_drop_final = baseline_ssim - final_results['SSIM']\n",
        "\n",
        "print(f\"   PSNR: {final_results['PSNR']:.3f} dB (Œî: {psnr_drop_final:.3f} dB)\")\n",
        "print(f\"   SSIM: {final_results['SSIM']:.4f} (Œî: {ssim_drop_final:.4f})\")\n",
        "print(f\"   Inference: {final_results['Inference_Time_ms']:.2f} ms\")\n",
        "print(f\"   FPS: {final_results['FPS']:.1f}\")\n",
        "print(f\"   Est. Param Reduction: ~{best_sparsity*100:.0f}%\")\n",
        "\n",
        "# Quality assessment\n",
        "if psnr_drop_final <= 0.5:\n",
        "    quality_verdict = \"‚úÖ EXCELLENT - No fine-tuning needed\"\n",
        "elif psnr_drop_final <= 1.0:\n",
        "    quality_verdict = \"‚úÖ GOOD - Optional fine-tuning\"\n",
        "elif psnr_drop_final <= 2.0:\n",
        "    quality_verdict = \"‚ö†Ô∏è  ACCEPTABLE - Fine-tuning recommended\"\n",
        "else:\n",
        "    quality_verdict = \"‚ùå POOR - Fine-tuning required\"\n",
        "\n",
        "print(f\"\\n{quality_verdict}\")\n",
        "\n",
        "# Save results\n",
        "results_summary = {\n",
        "    'baseline': {\n",
        "        'PSNR': baseline_psnr,\n",
        "        'SSIM': baseline_ssim,\n",
        "        'Parameters': count_parameters(model)\n",
        "    },\n",
        "    'pruned_corrected': {\n",
        "        'sparsity': best_sparsity,\n",
        "        'PSNR': final_results['PSNR'],\n",
        "        'SSIM': final_results['SSIM'],\n",
        "        'PSNR_drop': psnr_drop_final,\n",
        "        'SSIM_drop': ssim_drop_final,\n",
        "        'Inference_Time_ms': final_results['Inference_Time_ms'],\n",
        "        'FPS': final_results['FPS']\n",
        "    },\n",
        "    'all_experiments': {str(k): v for k, v in pruning_results_v2.items()}\n",
        "}\n",
        "\n",
        "with open('/content/pruning_results_corrected.json', 'w') as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "print(f\"\\nüíæ Results saved to '/content/pruning_results_corrected.json'\")\n",
        "\n",
        "# Save model\n",
        "torch.save({\n",
        "    'flownet_state_dict': final_pruned_model.flownet.state_dict(),\n",
        "    'sparsity': best_sparsity,\n",
        "    'masks': {k: v.numpy() for k, v in final_masks.items()},\n",
        "    'results': final_results\n",
        "}, '/content/pruned_model_corrected.pth')\n",
        "\n",
        "print(f\"üíæ Model saved to '/content/pruned_model_corrected.pth'\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ CORRECTED PRUNING COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Next steps recommendation\n",
        "print(\"\\nüìã NEXT STEPS:\")\n",
        "if psnr_drop_final <= 1.0:\n",
        "    print(\"   1. ‚úÖ Proceed to quantization (quality is good)\")\n",
        "    print(\"   2. Optional: Fine-tune for further improvement\")\n",
        "    print(\"   3. Implement video processing pipeline\")\n",
        "elif psnr_drop_final <= 2.0:\n",
        "    print(\"   1. ‚ö†Ô∏è  Fine-tune the pruned model (recommended)\")\n",
        "    print(\"   2. Then proceed to quantization\")\n",
        "    print(\"   3. Implement video processing pipeline\")\n",
        "else:\n",
        "    print(\"   1. ‚ùå Fine-tune the pruned model (required)\")\n",
        "    print(\"   2. Re-evaluate after fine-tuning\")\n",
        "    print(\"   3. Then consider quantization\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ============================================================\n",
        "# INTEGRATED TABLE EXPORT & DISPLAY (CSV + JSON)\n",
        "# ============================================================\n",
        "\n",
        "def status_from_psnr_drop(psnr_drop):\n",
        "    if psnr_drop <= 0.5:\n",
        "        return \"‚úÖ Excellent\"\n",
        "    elif psnr_drop <= 1.0:\n",
        "        return \"‚úÖ Good\"\n",
        "    elif psnr_drop <= 1.5:\n",
        "        return \"‚ö†Ô∏è Marginal\"\n",
        "    else:\n",
        "        return \"‚ùå Too high\"\n",
        "\n",
        "# DIAGNOSTIC TABLE\n",
        "diag_rows = []\n",
        "# Only add old row if old results exist\n",
        "try:\n",
        "    if not math.isnan(results_old['PSNR']):\n",
        "        diag_rows.append({\"Method\": \"Old method (inverted logic)\", \"PSNR_dB\": results_old['PSNR'], \"SSIM\": results_old['SSIM']})\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "diag_rows.append({\"Method\": \"New method (corrected)\", \"PSNR_dB\": results_new['PSNR'], \"SSIM\": results_new['SSIM']})\n",
        "diag_rows.append({\"Method\": \"Baseline\", \"PSNR_dB\": baseline_psnr, \"SSIM\": baseline_ssim})\n",
        "\n",
        "df_diag = pd.DataFrame(diag_rows)\n",
        "\n",
        "# PRUNING EXPERIMENTS TABLE\n",
        "rows = []\n",
        "for s, res in pruning_results_v2.items():\n",
        "    psnr = res['PSNR']\n",
        "    ssim = res['SSIM']\n",
        "    time_ms = res.get('Inference_Time_ms', float('nan'))\n",
        "    fps = res.get('FPS', float('nan'))\n",
        "    psnr_drop = baseline_psnr - psnr\n",
        "    ssim_drop = baseline_ssim - ssim\n",
        "    rows.append({\n",
        "        \"Sparsity\": f\"{s:.0%}\",\n",
        "        \"PSNR_dB\": round(psnr, 3),\n",
        "        \"PSNR_drop_dB\": round(psnr_drop, 3),\n",
        "        \"SSIM\": round(ssim, 4),\n",
        "        \"SSIM_drop\": round(ssim_drop, 4),\n",
        "        \"Inference_ms\": round(time_ms, 2),\n",
        "        \"FPS\": round(fps, 2),\n",
        "        \"Status\": status_from_psnr_drop(psnr_drop)\n",
        "    })\n",
        "\n",
        "df_prune = pd.DataFrame(rows).sort_values(by=\"Sparsity\")\n",
        "\n",
        "# FINAL SUMMARY TABLE\n",
        "final_summary = {\n",
        "    \"Baseline_PSNR_dB\": baseline_psnr,\n",
        "    \"Baseline_SSIM\": baseline_ssim,\n",
        "    \"Baseline_Params\": count_parameters(model),\n",
        "    \"Selected_Sparsity\": f\"{best_sparsity:.0%}\",\n",
        "    \"Final_PSNR_dB\": final_results['PSNR'],\n",
        "    \"Final_SSIM\": final_results['SSIM'],\n",
        "    \"PSNR_drop_dB\": round(baseline_psnr - final_results['PSNR'], 3),\n",
        "    \"SSIM_drop\": round(baseline_ssim - final_results['SSIM'], 4),\n",
        "    \"Inference_ms\": round(final_results['Inference_Time_ms'], 2),\n",
        "    \"FPS\": round(final_results['FPS'], 2),\n",
        "    \"Est_Param_Reduction_pct\": round(best_sparsity * 100, 1),\n",
        "    \"Quality_verdict\": quality_verdict\n",
        "}\n",
        "df_final = pd.DataFrame([final_summary]).T.reset_index()\n",
        "df_final.columns = [\"Metric\", \"Value\"]\n",
        "\n",
        "# Display the tables in the notebook\n",
        "display(Markdown(\"## Diagnostic comparison (old vs new)\"))\n",
        "display(df_diag)\n",
        "\n",
        "display(Markdown(\"## Pruning experiments\"))\n",
        "display(df_prune)\n",
        "\n",
        "display(Markdown(\"## Final summary\"))\n",
        "display(df_final)\n",
        "\n",
        "# Save to CSV and JSON for quick sharing\n",
        "out_dir = \"/content\"\n",
        "df_prune.to_csv(os.path.join(out_dir, 'pruning_experiments_table.csv'), index=False)\n",
        "df_diag.to_csv(os.path.join(out_dir, 'diagnostic_table.csv'), index=False)\n",
        "with open(os.path.join(out_dir, 'pruning_summary.json'), 'w') as f:\n",
        "    json.dump({\n",
        "        \"diagnostic\": diag_rows,\n",
        "        \"pruning_experiments\": rows,\n",
        "        \"final_summary\": final_summary\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved: \")\n",
        "print(f\" - {os.path.join(out_dir, 'pruning_experiments_table.csv')}\")\n",
        "print(f\" - {os.path.join(out_dir, 'diagnostic_table.csv')}\")\n",
        "print(f\" - {os.path.join(out_dir, 'pruning_summary.json')}\")"
      ],
      "metadata": {
        "id": "sGr7gY7Kk66x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89e68e9-3db1-4636-8fc6-f711c646275a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: DIAGNOSTIC - COMPARE OLD VS NEW PRUNING\n",
            "============================================================\n",
            "\n",
            "Computing channel importance...\n",
            "‚úÖ Analyzed 57 convolutional layers\n",
            "   Importance range: [1.89, 188.22], Mean: 73.84\n",
            "\n",
            "============================================================\n",
            "COMPARING METHODS AT 30% SPARSITY\n",
            "============================================================\n",
            "‚ÑπÔ∏è Old pruning functions not found; skipping old-method diagnostic.\n",
            "\n",
            "‚úÖ NEW METHOD (corrected logic):\n",
            "   Sparsity: 30.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 4800\n",
            "   Threshold: 40.152420\n",
            "   Logic: KEEP channels with importance >= 40.152420\n",
            "   Result: 4800/6858 channels kept (70.0%)\n",
            "   Actual sparsity: 30.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 2058/6858 channels (30.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PSNR: 23.118 dB\n",
            "   SSIM: 0.8412\n",
            "\n",
            "============================================================\n",
            "DIAGNOSTIC RESULT:\n",
            "============================================================\n",
            "‚ö†Ô∏è  MINIMAL DIFFERENCE: N/A dB\n",
            "   Issue might be elsewhere\n",
            "\n",
            "============================================================\n",
            "STEP 2: CORRECTED PRUNING EXPERIMENTS\n",
            "============================================================\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 10.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 10.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 6172\n",
            "   Threshold: 21.201897\n",
            "   Logic: KEEP channels with importance >= 21.201897\n",
            "   Result: 6172/6858 channels kept (90.0%)\n",
            "   Actual sparsity: 10.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 686/6858 channels (10.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 18.283 dB (drop: 17.009 dB)\n",
            "   SSIM: 0.6607 (drop: 0.3083)\n",
            "   Inference: 10.02 ms (99.8 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 20.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 20.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 5486\n",
            "   Threshold: 30.632299\n",
            "   Logic: KEEP channels with importance >= 30.632299\n",
            "   Result: 5486/6858 channels kept (80.0%)\n",
            "   Actual sparsity: 20.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 1372/6858 channels (20.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 18.658 dB (drop: 16.634 dB)\n",
            "   SSIM: 0.6846 (drop: 0.2844)\n",
            "   Inference: 12.39 ms (80.7 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 30.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 30.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 4800\n",
            "   Threshold: 40.152420\n",
            "   Logic: KEEP channels with importance >= 40.152420\n",
            "   Result: 4800/6858 channels kept (70.0%)\n",
            "   Actual sparsity: 30.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 2058/6858 channels (30.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 23.764 dB (drop: 11.528 dB)\n",
            "   SSIM: 0.8488 (drop: 0.1202)\n",
            "   Inference: 10.36 ms (96.5 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 40.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 40.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 4114\n",
            "   Threshold: 50.451553\n",
            "   Logic: KEEP channels with importance >= 50.451553\n",
            "   Result: 4114/6858 channels kept (60.0%)\n",
            "   Actual sparsity: 40.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 2744/6858 channels (40.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 30.409 dB (drop: 4.883 dB)\n",
            "   SSIM: 0.9552 (drop: 0.0138)\n",
            "   Inference: 9.96 ms (100.4 FPS)\n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "Testing sparsity: 50.0%\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   Sparsity: 50.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 3429\n",
            "   Threshold: 73.872589\n",
            "   Logic: KEEP channels with importance >= 73.872589\n",
            "   Result: 3429/6858 channels kept (50.0%)\n",
            "   Actual sparsity: 50.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 3429/6858 channels (50.0%)\n",
            "\n",
            "Evaluating on 50 samples...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Results:\n",
            "   PSNR: 30.919 dB (drop: 4.373 dB)\n",
            "   SSIM: 0.9572 (drop: 0.0118)\n",
            "   Inference: 10.81 ms (92.5 FPS)\n",
            "\n",
            "============================================================\n",
            "STEP 3: SELECTING OPTIMAL SPARSITY\n",
            "============================================================\n",
            "\n",
            "Sparsity   PSNR       Drop       SSIM       Status         \n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "10.0%      18.283     17.009     0.6607     ‚ùå Too high     \n",
            "20.0%      18.658     16.634     0.6846     ‚ùå Too high     \n",
            "30.0%      23.764     11.528     0.8488     ‚ùå Too high     \n",
            "40.0%      30.409     4.883      0.9552     ‚ùå Too high     \n",
            "50.0%      30.919     4.373      0.9572     ‚ùå Too high     \n",
            "\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "‚ö†Ô∏è  SELECTED: 10.0% sparsity (minimum)\n",
            "   PSNR: 18.283 dB (drop: 17.009 dB)\n",
            "   Note: All sparsity levels had high degradation\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "STEP 4: FULL EVALUATION ON UCF-101\n",
            "============================================================\n",
            "\n",
            "Creating final pruned model (10.0% sparsity)...\n",
            "   Sparsity: 10.0%\n",
            "   Total channels: 6858\n",
            "   Channels to keep: 6172\n",
            "   Threshold: 21.201897\n",
            "   Logic: KEEP channels with importance >= 21.201897\n",
            "   Result: 6172/6858 channels kept (90.0%)\n",
            "   Actual sparsity: 10.0%\n",
            "   Applied masks to 57 layers\n",
            "   Zeroed 686/6858 channels (10.0%)\n",
            "\n",
            "Evaluating on full UCF-101 dataset (379 sequences)...\n",
            "‚è±Ô∏è  This may take several minutes depending on your runtime and hardware...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "FINAL RESULTS - CORRECTED PRUNING\n",
            "============================================================\n",
            "\n",
            "üìä BASELINE MODEL:\n",
            "   PSNR: 35.292 dB\n",
            "   SSIM: 0.9690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Model' object has no attribute 'parameters'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1642329694.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   PSNR: {baseline_psnr:.3f} dB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   SSIM: {baseline_ssim:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Parameters: {count_parameters(model):,} ({count_parameters(model)/1e6:.2f}M)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nüìä PRUNED MODEL (Sparsity: {best_sparsity:.1%}):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1642329694.py\u001b[0m in \u001b[0;36mcount_parameters\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;31m# Simple parameter counting helper (if not already defined)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;31m# ============================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Model' object has no attribute 'parameters'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6-ET2CMziDS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}